# -*- coding: utf-8 -*-
"""Copia de SNS_ACT3_7_AdriánYaredArmasdelaNuez

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QhvP470pKO7eqk3aMk14n7VcF_xsHQ38

***Adrián Yared Armas de la Nuez***

**Problema de clasificación:**

*Original:*
https://www.drivendata.org/competitions/57/nepal-earthquake/


*Dataset zip link:*

*drive:*
https://drive.google.com/file/d/17d3uTOVUte5oeV3x41bQIfKnqtOqrZzG/view?usp=sharing

*git:*
https://github.com/AdrianYArmas/IaBigData/blob/main/SNS/3%20%20-%20Algoritmos%20y%20herramientas%20para%20el%20aprendizaje%20supervisado%20/3.7%20%20Predicci%C3%B3n%20de%20Riesgo%20de%20derrumbamiento_Terremotos/dataset/Earthquake_dataset.zip

# Imports
"""

!pip install lazypredict

# Importación de librerías necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.cluster import hierarchy
from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import f1_score, confusion_matrix, classification_report
from sklearn.model_selection import ParameterSampler
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier
from sklearn.svm import SVC
from lightgbm import LGBMClassifier
import lazypredict
from lazypredict.Supervised import LazyClassifier
import pickle
from sklearn.metrics import classification_report
# Importación de bibliotecas específicas para selección de características
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, SelectFromModel
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA
from tqdm.notebook import tqdm  # Para barras de progreso en notebook
# Si estás usando script y no notebook, usa:
# from tqdm import tqdm
import warnings

"""# Final code explained

## Datset
"""

warnings.filterwarnings('ignore')

# Configuración visual
plt.style.use('fivethirtyeight')
sns.set_palette("Set2")

"""### Download from github"""

# Download dataset from github
train_values_url = "https://raw.githubusercontent.com/AdrianYArmas/IaBigData/refs/heads/main/SNS/3%20%20-%20Algoritmos%20y%20herramientas%20para%20el%20aprendizaje%20supervisado%20/3.7%20%20Predicci%C3%B3n%20de%20Riesgo%20de%20derrumbamiento_Terremotos/dataset/train_values.csv"
train_labels_url = "https://raw.githubusercontent.com/AdrianYArmas/IaBigData/refs/heads/main/SNS/3%20%20-%20Algoritmos%20y%20herramientas%20para%20el%20aprendizaje%20supervisado%20/3.7%20%20Predicci%C3%B3n%20de%20Riesgo%20de%20derrumbamiento_Terremotos/dataset/train_labels.csv"
test_values_url  = "https://raw.githubusercontent.com/AdrianYArmas/IaBigData/refs/heads/main/SNS/3%20%20-%20Algoritmos%20y%20herramientas%20para%20el%20aprendizaje%20supervisado%20/3.7%20%20Predicci%C3%B3n%20de%20Riesgo%20de%20derrumbamiento_Terremotos/dataset/test_values.csv"

"""### Dataset Load"""

# Load datasets
train_values = pd.read_csv(train_values_url)
train_labels = pd.read_csv(train_labels_url)
test_values  = pd.read_csv(test_values_url)

print("Dimensions of training dataset (features):", train_values.shape)
print("Dimensions of training dataset (labels):", train_labels.shape)
print("Dimensions of test dataset:", test_values.shape)

# Display the first records
train_values.head()

"""### Data analysis"""

# Merge training data and labels for analysis
train_data = pd.merge(train_values, train_labels, on="building_id")

# Explore target variable distribution
plt.figure(figsize=(10, 6))
damage_counts = train_data['damage_grade'].value_counts().sort_index()
ax = damage_counts.plot(kind='bar', color=['lightgreen', 'orange', 'red'])
plt.title('Damage Class Distribution', fontsize=15)
plt.xlabel('Damage Level', fontsize=12)
plt.ylabel('Number of Buildings', fontsize=12)
plt.xticks(ticks=[0, 1, 2], labels=['Low (1)', 'Medium (2)', 'High (3)'], rotation=0)

# Add values above bars
for i, v in enumerate(damage_counts):
    ax.text(i, v + 50, str(v), ha='center', fontsize=10)

plt.tight_layout()
plt.show()

# Explore numerical features
numerical_features = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', 'count_floors_pre_eq',
                      'age', 'area_percentage', 'height_percentage']

fig, axes = plt.subplots(len(numerical_features), 1, figsize=(12, 4*len(numerical_features)))
for i, feature in enumerate(numerical_features):
    sns.boxplot(x='damage_grade', y=feature, data=train_data, ax=axes[i])
    axes[i].set_title(f'Distribution of {feature} by Damage Level', fontsize=14)
    axes[i].set_xlabel('Damage Level', fontsize=12)
    axes[i].set_ylabel(feature, fontsize=12)

plt.tight_layout()
plt.show()

# Correlation matrix of numerical features
plt.figure(figsize=(10, 8))
correlation_matrix = train_data[numerical_features + ['damage_grade']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix of Numerical Features', fontsize=15)
plt.tight_layout()
plt.show()

# Analysis of categorical features
categorical_features = ['land_surface_condition', 'foundation_type', 'roof_type',
                        'ground_floor_type', 'other_floor_type']

fig, axes = plt.subplots(len(categorical_features), 1, figsize=(14, 4*len(categorical_features)))
for i, feature in enumerate(categorical_features):
    # Calculate proportion of each category for each damage class
    cat_proportions = pd.crosstab(train_data[feature], train_data['damage_grade'],
                                  normalize='index') * 100
    cat_proportions.plot(kind='bar', stacked=True, ax=axes[i],
                         color=['lightgreen', 'orange', 'red'])
    axes[i].set_title(f'Class Proportion by {feature}', fontsize=14)
    axes[i].set_xlabel(feature, fontsize=12)
    axes[i].set_ylabel('Percentage (%)', fontsize=12)
    axes[i].legend(title='Damage Level', labels=['Low (1)', 'Medium (2)', 'High (3)'])

plt.tight_layout()
plt.show()

# Identify binary columns (encoded as 0-1)
binary_columns = []
for col in train_values.columns:
    unique_vals = train_values[col].unique()
    if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1}):
        binary_columns.append(col)

print(f"{len(binary_columns)} binary columns identified")

# Statistical summary of important numerical features
train_data[numerical_features].describe()

"""## Selection ussing dendrograms"""

# Select numerical features for analysis
X_scaled = StandardScaler().fit_transform(train_data[numerical_features])

# Create and visualize the dendrogram for feature clustering
plt.figure(figsize=(14, 10))
dend = hierarchy.dendrogram(
    hierarchy.linkage(X_scaled.T, method='ward'),
    labels=numerical_features,
    orientation='right',
    leaf_font_size=12,
    color_threshold=5
)
plt.title('Dendrogram of Numerical Features', fontsize=16)
plt.xlabel('Distance', fontsize=14)
plt.axvline(x=5, color='red', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Convert categorical features to numerical for correlation analysis
def convert_categorical_to_numeric(df, categorical_cols):
    return df[categorical_cols].apply(lambda col: col.astype('category').cat.codes)

categorical_cols = [col for col in train_data.columns if train_data[col].dtype == 'object' and col != 'building_id']
train_data_encoded = train_data.copy()
train_data_encoded[categorical_cols] = convert_categorical_to_numeric(train_data, categorical_cols)

# Select a subset of features for correlation matrix
selected_features = numerical_features + categorical_cols[:5] + ['damage_grade']

# Compute and visualize the correlation matrix
plt.figure(figsize=(14, 12))
correlation = train_data_encoded[selected_features].corr()
sns.heatmap(correlation, mask=np.triu(np.ones_like(correlation, dtype=bool)),
            annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5, vmin=-1, vmax=1)
plt.title('Correlation Matrix Between Features and Target Variable', fontsize=16)
plt.tight_layout()
plt.show()

# Select relevant features based on dendrogram and correlation analysis
selected_features = [
    'count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',
    'land_surface_condition', 'foundation_type', 'roof_type',
    'ground_floor_type', 'other_floor_type'
]

# Include top 10 binary features
selected_features += binary_columns[:10]

print("Selected features for modeling:", selected_features)

"""## Selection without ussing dendrograms"""

# 1. Prepare the data for feature selection
X_encoded = convert_categorical_to_numeric(train_data, categorical_cols).drop(['building_id'], axis=1)
y = train_data['damage_grade']  # Target variable

# 2. F-Test (ANOVA) for feature selection
print("\n--- Feature Selection Based on F-Test (ANOVA) ---")
selector_f = SelectKBest(f_classif, k=20)
X_kbest = selector_f.fit_transform(X_encoded, y)
feature_scores_f = pd.DataFrame({'Feature': X_encoded.columns, 'F-Score': selector_f.scores_, 'P-Value': selector_f.pvalues_})
top_features_f = feature_scores_f.sort_values('F-Score', ascending=False).head(20)
print("Top 20 features according to F-Test:")
display(top_features_f)

# Plot the top 15 features
plt.figure(figsize=(12, 8))
sns.barplot(x='F-Score', y='Feature', data=top_features_f.head(15))
plt.title('Top 15 Features Based on F-Test (ANOVA)', fontsize=15)
plt.tight_layout()
plt.show()

# 3. Mutual Information for feature selection
print("\n--- Feature Selection Based on Mutual Information ---")
selector_mi = SelectKBest(mutual_info_classif, k=20)
X_mi = selector_mi.fit_transform(X_encoded, y)
feature_scores_mi = pd.DataFrame({'Feature': X_encoded.columns, 'Mutual Information': selector_mi.scores_})
top_features_mi = feature_scores_mi.sort_values('Mutual Information', ascending=False).head(20)
print("Top 20 features according to Mutual Information:")
display(top_features_mi)

# Plot the top 15 features
plt.figure(figsize=(12, 8))
sns.barplot(x='Mutual Information', y='Feature', data=top_features_mi.head(15))
plt.title('Top 15 Features Based on Mutual Information', fontsize=15)
plt.tight_layout()
plt.show()

# 4. Feature Importance using RandomForest
print("\n--- Feature Selection Based on RandomForest Importance ---")
feature_selector_rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
feature_selector_rf.fit(X_encoded, y)
feature_importances = pd.DataFrame({'Feature': X_encoded.columns, 'Importance': feature_selector_rf.feature_importances_})
top_features_rf = feature_importances.sort_values('Importance', ascending=False).head(20)
print("Top 20 features according to RandomForest:")
display(top_features_rf)

# Plot the top 15 most important features
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=top_features_rf.head(15))
plt.title('Top 15 Features Based on Random Forest', fontsize=15)
plt.tight_layout()
plt.show()

# 5. Automatically select features above the average importance threshold
selector_model = SelectFromModel(feature_selector_rf, threshold='mean')
selected_features = X_encoded.columns[selector_model.fit_transform(X_encoded, y).get_support()]
print(f"\nAutomatically selected features by RandomForest: {len(selected_features)}")
print(sorted(selected_features))

# 6. Principal Component Analysis (PCA)
print("\n--- Principal Component Analysis (PCA) ---")
X_pca = PCA().fit_transform(StandardScaler().fit_transform(X_encoded))
cumulative_variance_ratio = np.cumsum(PCA().explained_variance_ratio_)
n_components_95 = np.argmax(cumulative_variance_ratio >= 0.95) + 1
print(f"Number of components needed to explain 95% of the variance: {n_components_95}")

# Plot cumulative explained variance
plt.figure(figsize=(12, 6))
plt.plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, marker='o', linestyle='-')
plt.axhline(y=0.95, color='r', linestyle='--')
plt.axvline(x=n_components_95, color='g', linestyle='--')
plt.text(n_components_95 + 1, 0.85, f'95% with {n_components_95} components', fontsize=12)
plt.title('Cumulative Explained Variance vs Number of Components', fontsize=15)
plt.xlabel('Number of Components', fontsize=12)
plt.ylabel('Cumulative Explained Variance', fontsize=12)
plt.grid(True)
plt.tight_layout()
plt.show()

# 7. Common features across methods
common_features_anova_mi = set(top_features_f['Feature']).intersection(top_features_mi['Feature'])
common_features_anova_rf = set(top_features_f['Feature']).intersection(top_features_rf['Feature'])
common_features_mi_rf = set(top_features_mi['Feature']).intersection(top_features_rf['Feature'])
common_features_all = common_features_anova_mi.intersection(top_features_rf['Feature'])

print("\n--- Common Features Across Selection Methods ---")
print(f"Common features in ANOVA and MI: {len(common_features_anova_mi)}")
print(f"Common features in ANOVA and RF: {len(common_features_anova_rf)}")
print(f"Common features in MI and RF: {len(common_features_mi_rf)}")
print(f"Common features in all three methods: {len(common_features_all)}")
print("Features selected by all three methods:", sorted(common_features_all))

# 8. Final feature selection combining different methods
selected_features_from_dendrogram = selected_features  # Features identified earlier from clustering
selected_features_from_statistical = list(common_features_anova_mi.union(common_features_anova_rf, common_features_mi_rf))
final_selected_features = list(set(selected_features_from_dendrogram).union(selected_features_from_statistical))

print("\n--- Final Feature Selection ---")
print(f"Total selected features: {len(final_selected_features)}")
print("Final list of selected features:", sorted(final_selected_features))

"""##  Preprocesamiento de datos y selección de muestra"""

# Preprocessing the data
X = train_data.drop(['building_id', 'damage_grade'], axis=1)  # Drop irrelevant columns
y = train_data['damage_grade']  # Target variable

# Identify categorical and numerical columns
categorical_cols = X.select_dtypes(include='object').columns
numerical_cols = X.select_dtypes(exclude='object').columns

# Explanation of the sampling strategy
print("Sampling strategy:\n- Stratified sampling with geographic diversity and structural characteristics.")

# Advanced sampling function to ensure diverse and representative samples
def advanced_sampling(df, y, sample_size):
    geo_groups = df.groupby(['geo_level_1_id', 'geo_level_2_id'])
    sampled_indices = []

    for name, group in geo_groups:
        group_size = len(group)
        group_sample_size = max(1, int(group_size / len(df) * sample_size))

        for damage_level in [1, 2, 3]:
            damage_indices = group[y == damage_level].index
            if len(damage_indices) > 0:
                damage_sample_size = max(1, int(group_sample_size * (sum(y[group.index] == damage_level) / group_size)))
                sorted_indices = df.loc[damage_indices].sort_values(by=['age', 'count_floors_pre_eq', 'area_percentage']).index[:damage_sample_size]
                sampled_indices.extend(sorted_indices)

    if len(sampled_indices) < sample_size:
        remaining = sample_size - len(sampled_indices)
        additional_indices = df.sort_values(by=['foundation_type', 'roof_type', 'height_percentage']).index[:remaining]
        sampled_indices.extend(additional_indices)

    return df.loc[sampled_indices], y.loc[sampled_indices]

# Calculate the sample size (2% of the total dataset)
sample_size = int(0.02 * len(train_data))

# Apply the advanced sampling method
X_sampled, y_sampled = advanced_sampling(X, y, sample_size)

# Check class distribution in the sampled data
plt.figure(figsize=(10, 6))
sns.countplot(x=y_sampled, palette=['lightgreen', 'orange', 'red'])
plt.title('Class Distribution in the Selected Sample', fontsize=15)
plt.xticks([0, 1, 2], ['Low (1)', 'Medium (2)', 'High (3)'])
plt.tight_layout()
plt.show()

# Split data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X_sampled, y_sampled, test_size=0.2, random_state=42, stratify=y_sampled)

# Display sizes of training and testing sets
print(f"Training set size: {X_train.shape[0]} samples")
print(f"Test set size: {X_test.shape[0]} samples")

# Define preprocessor for scaling and encoding
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numerical_cols),  # Scale numerical features
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)  # One-hot encode categorical features
])

# Apply preprocessing to the training and test data
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

# Save preprocessor for future use
with open('preprocessor.pkl', 'wb') as file:
    pickle.dump(preprocessor, file)

"""## Lazy predict"""

# Run LazyPredict to quickly compare multiple models
clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)

# Fit models to the training and testing data
models, predictions = clf.fit(X_train_processed, X_test_processed, y_train, y_test)

# Display the results of all models
print("Model Comparison using LazyPredict:")
display(models)

# Visualizing the top 15 models by accuracy
plt.figure(figsize=(12, 8))
# Sort models by accuracy and select the top 15
models_accuracy = models.sort_values(by='Accuracy', ascending=False)[:15]
# Create a barplot for accuracy
sns.barplot(x=models_accuracy.index, y=models_accuracy['Accuracy'], palette='viridis')
plt.title('Top 15 Models by Accuracy', fontsize=15)
plt.xticks(rotation=90, fontsize=10)  # Rotate labels for better readability
plt.ylabel('Accuracy', fontsize=12)
plt.tight_layout()
plt.show()

# Visualizing the top 15 models by F1-Score (our main evaluation metric)
plt.figure(figsize=(12, 8))
# Sort models by F1-Score and select the top 15
models_f1 = models.sort_values(by='F1 Score', ascending=False)[:15]
# Create a barplot for F1-Score
sns.barplot(x=models_f1.index, y=models_f1['F1 Score'], palette='plasma')
plt.title('Top 15 Models by F1-Score', fontsize=15)
plt.xticks(rotation=90, fontsize=10)  # Rotate labels for better readability
plt.ylabel('F1-Score', fontsize=12)
plt.tight_layout()
plt.show()

"""## Models

### Tree Models

#### BeggingClassifier
"""

# First, we’ll set up our model using a DecisionTree as the base estimator inside a BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
base_estimator = DecisionTreeClassifier(random_state=42)
bagging_model = BaggingClassifier(estimator=base_estimator, random_state=42, n_jobs=-1)

# Now, we define the parameters that we'll test to optimize the model.
param_dist_bagging = {
    'n_estimators': [10, 50, 100],  # Number of base estimators (trees) in the bagging ensemble
    'max_samples': [0.5, 0.7, 1.0],  # Fraction of samples to train each base estimator on
    'max_features': [0.5, 0.7, 1.0],  # Fraction of features to use for each base estimator
    'bootstrap': [True, False],  # Whether or not to sample with replacement
    'estimator__max_depth': [None, 10, 20],  # Maximum depth of each tree (helps prevent overfitting)
    'estimator__min_samples_split': [2, 5, 10],  # Minimum samples needed to split an internal node
    'estimator__min_samples_leaf': [1, 2, 4]  # Minimum samples needed to be at a leaf node
}

# We generate random combinations of the above parameters to try out
param_list = list(ParameterSampler(param_dist_bagging, n_iter=20, random_state=42))

# We will store the results of each parameter combination here
best_score = 0
best_params = None
results = []

# Set up cross-validation with 3 splits
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

# We’ll now run a loop to optimize the BaggingClassifier model
print("Starting optimization for BaggingClassifier... (you’ll see the progress here!)")
for params in tqdm(param_list, desc="Optimizing BaggingClassifier"):
    # We separate parameters for the base estimator and the BaggingClassifier itself
    estimator_params = {}
    bagging_params = {}

    for key, value in params.items():
        if key.startswith('estimator__'):
            # Extract the parameter name without the 'estimator__' prefix
            param_name = key.replace('estimator__', '')
            estimator_params[param_name] = value
        else:
            bagging_params[key] = value

    # Now, create the base estimator (decision tree) with the extracted parameters
    base_est = DecisionTreeClassifier(random_state=42, **estimator_params)

    # Create the BaggingClassifier with the base estimator and other parameters
    model = BaggingClassifier(estimator=base_est, random_state=42, n_jobs=-1, **bagging_params)

    scores = []

    # Perform manual cross-validation
    for train_idx, val_idx in cv.split(X_train_processed, y_train):
        # Extract the data for this fold
        X_fold_train, X_fold_val = X_train_processed[train_idx], X_train_processed[val_idx]
        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]

        # Train the model on the fold's training data and make predictions
        model.fit(X_fold_train, y_fold_train)
        y_pred = model.predict(X_fold_val)

        # Calculate the F1-score for the fold
        score = f1_score(y_fold_val, y_pred, average='micro')
        scores.append(score)

    # Calculate the average F1-score across all folds
    mean_score = np.mean(scores)
    results.append((params, mean_score))

    # If this model has the best score so far, we save it
    if mean_score > best_score:
        best_score = mean_score
        best_params = params
        print(f"\nNew best F1-score: {best_score:.4f} with these parameters:")
        for key, value in params.items():
            print(f"  {key}: {value}")

# After testing all the parameter combinations, we'll create the final model using the best parameters
# Separate the best parameters for the base estimator and BaggingClassifier
estimator_params = {}
bagging_params = {}

for key, value in best_params.items():
    if key.startswith('estimator__'):
        param_name = key.replace('estimator__', '')
        estimator_params[param_name] = value
    else:
        bagging_params[key] = value

# Create the final base estimator with the best parameters
best_base_estimator = DecisionTreeClassifier(random_state=42, **estimator_params)

# Create the final BaggingClassifier model
best_bagging = BaggingClassifier(
    estimator=best_base_estimator,
    random_state=42,
    n_jobs=-1,
    **bagging_params
)

# Train the final model on the full training set
best_bagging.fit(X_train_processed, y_train)

# Output the details about the best model and its parameters
print("\nTraining complete.")
print("Best parameters for BaggingClassifier:")
print("Base estimator parameters:")
for key, value in estimator_params.items():
    print(f"  {key}: {value}")
print("Bagging parameters:")
for key, value in bagging_params.items():
    print(f"  {key}: {value}")
print(f"Best F1-score in cross-validation: {best_score:.4f}")

# Evaluate the trained model on the test set
y_pred_bagging = best_bagging.predict(X_test_processed)

# Calculate and print the F1-score on the test set
bagging_f1 = f1_score(y_test, y_pred_bagging, average='micro')
print(f"F1-score (micro) on test set: {bagging_f1:.4f}")

# Visualize the confusion matrix to see how well the model performed on each class
plt.figure(figsize=(10, 8))
conf_matrix = confusion_matrix(y_test, y_pred_bagging)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens',
            xticklabels=['Low (1)', 'Medium (2)', 'High (3)'],
            yticklabels=['Low (1)', 'Medium (2)', 'High (3)'])
plt.title('Confusion Matrix - BaggingClassifier', fontsize=15)
plt.ylabel('True Class', fontsize=12)
plt.xlabel('Predicted Class', fontsize=12)
plt.tight_layout()
plt.show()

# Print a detailed classification report for further analysis
print("Classification report - BaggingClassifier:")
print(classification_report(y_test, y_pred_bagging))

# Save the trained model to a file for future use
with open('bagging_model.pkl', 'wb') as file:
    pickle.dump(best_bagging, file)

"""#### LGBMClassifier"""

# Setting up the initial model with a focus on high precision
lgbm_model = LGBMClassifier(random_state=42, n_jobs=-1)

# Define the parameter grid with a focus on general accuracy
param_dist_lgbm = {
    'n_estimators': [300, 500, 700, 1000],  # More trees for stability
    'learning_rate': [0.01, 0.05, 0.1],  # Varying learning rates
    'max_depth': [7, 9, 11],  # Moderate depths
    'num_leaves': [31, 63, 127],  # Different leaf configurations
    'min_child_samples': [20, 50, 100],  # Higher values to prevent overfitting
    'subsample': [0.8, 0.9, 1.0],  # Complete sampling to avoid bias
    'colsample_bytree': [0.8, 0.9, 1.0],  # Feature sampling options
    'min_split_gain': [0.0, 0.01],  # Control split gains
    'reg_alpha': [0.0, 0.1, 1.0],  # Stronger L1 regularization
    'reg_lambda': [0.0, 0.1, 1.0],  # Stronger L2 regularization
    'boosting': ['gbdt', 'dart'],  # Different boosting algorithms to try
    'verbose': [-1]  # Suppress verbosity
}

# Create random combinations of these parameters for optimization
param_list = list(ParameterSampler(param_dist_lgbm, n_iter=30, random_state=42))

# Variables to track the best performance
best_accuracy = 0
best_params = None
results = []

# Setting up cross-validation
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

# Starting the optimization loop
print("Starting optimization for maximum accuracy...")
for params in tqdm(param_list, desc="Optimizing LGBMClassifier for accuracy"):
    model = LGBMClassifier(random_state=42, n_jobs=-1, **params)
    accuracies = []
    f1_scores = []

    # Perform manual cross-validation
    for train_idx, val_idx in cv.split(X_train_processed, y_train):
        # Get training and validation data for this fold
        X_fold_train, X_fold_val = X_train_processed[train_idx], X_train_processed[val_idx]
        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]

        # Train the model and evaluate performance
        model.fit(X_fold_train, y_fold_train)
        y_pred = model.predict(X_fold_val)

        # Calculate accuracy and F1-score for this fold
        acc = accuracy_score(y_fold_val, y_pred)
        f1 = f1_score(y_fold_val, y_pred, average='micro')

        accuracies.append(acc)
        f1_scores.append(f1)

    # Calculate average metrics across all folds
    mean_accuracy = np.mean(accuracies)
    mean_f1 = np.mean(f1_scores)

    results.append((params, mean_accuracy, mean_f1))

    # Update the best model if this one is better
    if mean_accuracy > best_accuracy:
        best_accuracy = mean_accuracy
        best_params = params
        print(f"\nNew accuracy record: {best_accuracy:.4f} with parameters:")
        for key, value in params.items():
            if key != 'verbose':  # Skip parameters not relevant to output
                print(f"  {key}: {value}")
        print(f"Associated F1-score: {mean_f1:.4f}")

# Create the best model using the optimal parameters
best_lgbm = LGBMClassifier(random_state=42, n_jobs=-1, **best_params)

# Train the final model on the entire training dataset
print("\nTraining the final model with the best parameters...")
best_lgbm.fit(X_train_processed, y_train)

print("\nTraining complete.")
print(f"Best parameters for maximum accuracy: {best_params}")
print(f"Best accuracy in cross-validation: {best_accuracy:.4f}")

# Evaluate the final model on the test set
y_pred_lgbm = best_lgbm.predict(X_test_processed)

# Print detailed evaluation metrics
accuracy = accuracy_score(y_test, y_pred_lgbm)
lgbm_f1 = f1_score(y_test, y_pred_lgbm, average='micro')
lgbm_f1_per_class = f1_score(y_test, y_pred_lgbm, average=None)

print(f"\nTest set results:")
print(f"Accuracy: {accuracy:.4f}")
print(f"F1-score (micro): {lgbm_f1:.4f}")
print(f"F1-score per class: Class 1: {lgbm_f1_per_class[0]:.4f}, Class 2: {lgbm_f1_per_class[1]:.4f}, Class 3: {lgbm_f1_per_class[2]:.4f}")

# Plot confusion matrix for better understanding of misclassifications
plt.figure(figsize=(10, 8))
conf_matrix = confusion_matrix(y_test, y_pred_lgbm)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Low (1)', 'Medium (2)', 'High (3)'],
            yticklabels=['Low (1)', 'Medium (2)', 'High (3)'])
plt.title('Confusion Matrix - LGBMClassifier Maximum Accuracy', fontsize=15)
plt.ylabel('True Class', fontsize=12)
plt.xlabel('Predicted Class', fontsize=12)
plt.tight_layout()
plt.show()

# Detailed classification report
print("\nClassification report - Optimized LGBMClassifier for Accuracy:")
print(classification_report(y_test, y_pred_lgbm))

# Learning curve for further analysis (optional)
if 'n_estimators' in best_params:
    n_estimators = best_params['n_estimators']
    learning_rates = [0.01, 0.05, 0.1, 0.2]

    plt.figure(figsize=(12, 8))
    for lr in learning_rates:
        eval_set = [(X_test_processed, y_test)]
        model = LGBMClassifier(
            n_estimators=n_estimators,
            learning_rate=lr,
            random_state=42,
            n_jobs=-1,
            verbose=-1
        )
        model.fit(X_train_processed, y_train,
                 eval_set=eval_set,
                 eval_metric='multi_logloss')  # Suppress verbosity during fit()

        results = model.evals_result_['valid_0']['multi_logloss']
        plt.plot(range(1, len(results) + 1), results, label=f'learning_rate={lr}')

    plt.xlabel('Number of Trees')
    plt.ylabel('Log Loss')
    plt.title('Effect of Learning Rate on Model Performance')
    plt.legend()
    plt.grid(True)
    plt.show()

# Feature importance analysis to understand model behavior
plt.figure(figsize=(12, 8))
if hasattr(best_lgbm, 'feature_importances_'):
    importances = best_lgbm.feature_importances_
    indices = np.argsort(importances)[-20:]  # Top 20 features
    plt.barh(range(len(indices)), importances[indices])
    plt.yticks(range(len(indices)), [f'Feature {i}' for i in indices])
    plt.title('Top 20 Important Features - High Precision Model', fontsize=15)
    plt.xlabel('Importance', fontsize=12)
    plt.tight_layout()
    plt.show()

# Save the final high-precision model for future use
with open('lgbm_model_high_precision.pkl', 'wb') as file:
    pickle.dump(best_lgbm, file)

"""#### Randomforest"""

# Initialize the RandomForestClassifier model
rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)

# Define the parameters for hyperparameter search (tuning)
param_dist_rf = {
    'n_estimators': [100, 200, 300],  # Number of trees in the forest
    'max_depth': [None, 10, 20, 30],  # Maximum depth of the trees
    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node
    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required in a leaf
    'max_features': ['sqrt', 'log2']  # Feature selection for splitting each tree
}

# Generate random combinations of parameters
param_list = list(ParameterSampler(param_dist_rf, n_iter=20, random_state=42))

# Initialize variables to store the best result
best_score = 0
best_params = None
results = []

# Set up cross-validation with 3 folds
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

# Loop with progress bar to optimize RandomForest
print("Starting optimization for RandomForestClassifier with progress visualization...")
for params in tqdm(param_list, desc="Optimizing RandomForest"):
    model = RandomForestClassifier(random_state=42, n_jobs=-1, **params)
    scores = []

    # Perform manual cross-validation
    for train_idx, val_idx in cv.split(X_train_processed, y_train):
        # Split the data into training and validation sets based on the indices
        if isinstance(X_train_processed, np.ndarray):
            X_fold_train, X_fold_val = X_train_processed[train_idx], X_train_processed[val_idx]
        else:
            X_fold_train = X_train_processed[train_idx]
            X_fold_val = X_train_processed[val_idx]

        y_fold_train = y_train.iloc[train_idx]
        y_fold_val = y_train.iloc[val_idx]

        # Train and evaluate the model
        model.fit(X_fold_train, y_fold_train)
        y_pred = model.predict(X_fold_val)
        score = f1_score(y_fold_val, y_pred, average='micro')  # Use F1-score as the metric
        scores.append(score)

    # Calculate the average F1-score for this set of parameters
    mean_score = np.mean(scores)
    results.append((params, mean_score))

    # If we find a better model, update the results
    if mean_score > best_score:
        best_score = mean_score
        best_params = params
        print(f"\nNew best F1-score: {best_score:.4f} with parameters:")
        for key, value in params.items():
            print(f"  {key}: {value}")

# Create the final model with the best parameters found
best_rf = RandomForestClassifier(random_state=42, n_jobs=-1, **best_params)
best_rf.fit(X_train_processed, y_train)

# Training information
print("\nTraining complete.")
print(f"Best parameters for RandomForestClassifier: {best_params}")
print(f"Best F1-score in cross-validation: {best_score:.4f}")

# Evaluate the model on the test set
y_pred_rf = best_rf.predict(X_test_processed)

# Calculate the F1-score on the test set
rf_f1 = f1_score(y_test, y_pred_rf, average='micro')
print(f"F1-score (micro) on the test set: {rf_f1:.4f}")

# Visualize the confusion matrix to evaluate model performance
plt.figure(figsize=(10, 8))
conf_matrix = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Oranges',
            xticklabels=['Low (1)', 'Medium (2)', 'High (3)'],
            yticklabels=['Low (1)', 'Medium (2)', 'High (3)'])
plt.title('Confusion Matrix - Random Forest', fontsize=15)
plt.ylabel('Actual Class', fontsize=12)
plt.xlabel('Predicted Class', fontsize=12)
plt.tight_layout()
plt.show()

# Display the classification report
print("Classification Report - Random Forest:")
print(classification_report(y_test, y_pred_rf))

# Visualization of the most important features according to the model
if hasattr(best_rf, 'feature_importances_'):
    # Get the feature importances
    importances = best_rf.feature_importances_
    indices = np.argsort(importances)[-20:]  # Top 20 most important features

    # Plot the top 20 most important features
    plt.figure(figsize=(12, 8))
    plt.barh(range(len(indices)), importances[indices])
    plt.yticks(range(len(indices)), [f'Feature {i}' for i in indices])
    plt.title('Top 20 Most Important Features - Random Forest', fontsize=15)
    plt.xlabel('Importance', fontsize=12)
    plt.tight_layout()
    plt.show()

# Save the trained model for later use
with open('random_forest_model.pkl', 'wb') as file:
    pickle.dump(best_rf, file)

"""### SVC"""

# start by setting up the SVC (Support Vector Classifier) model with the option to output probabilities
svm_model = SVC(probability=True, random_state=42)

# We'll define the hyperparameters we want to test for the model
param_dist_svm = {
    'C': [0.1, 1, 10],  # This controls how strictly we separate the classes (regularization)
    'kernel': ['linear', 'rbf'],  # The type of decision boundary we want (linear or more flexible 'rbf')
    'gamma': ['scale', 'auto', 0.1]  # Controls how much influence each training point has on the decision boundary
}

# If we have more than 5000 samples, we'll use a smaller subset to speed up training
if X_train_processed.shape[0] > 5000:
    from sklearn.model_selection import train_test_split
    # Take a random sample of 5000 samples to train the model (just for quicker experimentation)
    X_train_svm, _, y_train_svm, _ = train_test_split(
        X_train_processed, y_train,
        train_size=5000,  # Limit to 5000 samples
        random_state=42,
        stratify=y_train  # Make sure the classes are proportionally represented in the sample
    )
    print(f"Using a subset of {X_train_svm.shape[0]} samples to train the SVM")
else:
    # If there aren't many samples, just use all of them
    X_train_svm = X_train_processed
    y_train_svm = y_train

# Generate random combinations of the hyperparameters to explore
param_list = list(ParameterSampler(param_dist_svm, n_iter=10, random_state=42))

# Variables to keep track of the best model we've found
best_score = 0
best_params = None
results = []

# We'll use cross-validation to test the model's performance
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

# This loop will try different combinations of hyperparameters and evaluate them
print("Starting optimization for SVC with progress visualization...")
for params in tqdm(param_list, desc="Optimizing SVC"):
    model = SVC(probability=True, random_state=42, **params)
    scores = []

    # Train and evaluate the model on different folds of the data
    for train_idx, val_idx in cv.split(X_train_svm, y_train_svm):
        # Split the data into training and validation sets for this fold
        X_fold_train, X_fold_val = X_train_svm[train_idx], X_train_svm[val_idx]
        y_fold_train, y_fold_val = y_train_svm.iloc[train_idx], y_train_svm.iloc[val_idx]

        # Train the model on the training fold and make predictions on the validation fold
        model.fit(X_fold_train, y_fold_train)
        y_pred = model.predict(X_fold_val)

        # Calculate the F1-score for this fold
        score = f1_score(y_fold_val, y_pred, average='micro')
        scores.append(score)

    # Calculate the average F1-score across all folds
    mean_score = np.mean(scores)
    results.append((params, mean_score))

    # If we found a better model, keep track of it
    if mean_score > best_score:
        best_score = mean_score
        best_params = params
        print(f"\nNew best F1-score: {best_score:.4f} with parameters:")
        for key, value in params.items():
            print(f"  {key}: {value}")

# Now that we've found the best parameters, let's train the model with the full training set
best_svm = SVC(probability=True, random_state=42, **best_params)
print("\nTraining the final SVC model with the full dataset...")
best_svm.fit(X_train_processed, y_train)

# Output some details about the model training
print("\nTraining complete.")
print(f"Best parameters for SVC: {best_params}")
print(f"Best F1-score in cross-validation: {best_score:.4f}")

# Evaluate the trained model on the test set to see how it performs on unseen data
y_pred_svm = best_svm.predict(X_test_processed)

# Calculate the F1-score for the test set predictions
svm_f1 = f1_score(y_test, y_pred_svm, average='micro')
print(f"F1-score (micro) on the test set: {svm_f1:.4f}")

# Visualize how well the model predicted each class using a confusion matrix
plt.figure(figsize=(10, 8))
conf_matrix = confusion_matrix(y_test, y_pred_svm)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Purples',
            xticklabels=['Low (1)', 'Medium (2)', 'High (3)'],
            yticklabels=['Low (1)', 'Medium (2)', 'High (3)'])
plt.title('Confusion Matrix - SVM', fontsize=15)
plt.ylabel('True Class', fontsize=12)
plt.xlabel('Predicted Class', fontsize=12)
plt.tight_layout()
plt.show()

# Print a detailed classification report (Precision, Recall, F1-score for each class)
print("Classification report - SVM:")
print(classification_report(y_test, y_pred_svm))

# Save the trained model for later use
with open('svm_model.pkl', 'wb') as file:
    pickle.dump(best_svm, file)

"""### Comparación modelos"""

# Define F1-score of LGBMClassifier with RandomizedSearchCV
lgbm_randomized_f1 = 0.7198

# Collect metrics of selected models
model_names = ['LGBMClassifier (GridSearch)', 'LGBMClassifier (RandomizedSearch)', 'RandomForest', 'SVM']
f1_scores_test = [lgbm_f1, lgbm_randomized_f1, rf_f1, svm_f1]

# Create DataFrame for visual comparison
comparison_df = pd.DataFrame({
    'Model': model_names,
    'F1-Score (Test)': f1_scores_test,
})

# Display comparison table
print("Model Comparison by F1-Score:")
display(comparison_df.sort_values(by='F1-Score (Test)', ascending=False))

# Visualization of F1-Score comparison
plt.figure(figsize=(12, 6))
sns.barplot(x='Model', y='F1-Score (Test)', data=comparison_df.sort_values(by='F1-Score (Test)', ascending=False), palette='viridis')
plt.title('Model Comparison by F1-Score', fontsize=15)
plt.ylabel('F1-Score', fontsize=12)
plt.xticks(rotation=15, ha='right')
plt.ylim(min(f1_scores_test) - 0.05, 1.0)  # Adjust lower limit for better visualization
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Add value labels above the bars
for i, model in enumerate(comparison_df.sort_values(by='F1-Score (Test)', ascending=False)['Model']):
    idx = model_names.index(model)
    plt.text(i, f1_scores_test[idx] + 0.01, f'{f1_scores_test[idx]:.4f}', ha='center', fontsize=9)

plt.tight_layout()
plt.show()

# Determine the best model based on the test set
best_model_idx = f1_scores_test.index(max(f1_scores_test))
best_model_name = model_names[best_model_idx]

print(f"The best model is: {best_model_name} with F1-Score of {max(f1_scores_test):.4f}")

# Specific comparison between LGBMClassifier implementations (GridSearch vs RandomizedSearch)
print("\nComparison between LGBMClassifier implementations:")
lgbm_comparison = comparison_df[comparison_df['Model'].str.contains('LGBMClassifier')]
display(lgbm_comparison)

# Comparative visualization of F1-Score by class between GridSearch and RandomizedSearch
lgbm_grid_f1_classes = [0.5013, 0.7758, 0.6845]
lgbm_random_f1_classes = [0.49, 0.78, 0.69]

# Create DataFrame with class-wise comparison
class_comparison = pd.DataFrame({
    'Class': ['Low (1)', 'Medium (2)', 'High (3)'] * 2,
    'Model': ['GridSearch'] * 3 + ['RandomizedSearch'] * 3,
    'F1_Score': lgbm_grid_f1_classes + lgbm_random_f1_classes
})

# F1-Score by class visualization
plt.figure(figsize=(12, 7))
sns.barplot(x='Class', y='F1_Score', hue='Model', data=class_comparison, palette=['#2C7FB8', '#7FBC41'])
plt.title('Comparison of F1-Score by Class: GridSearch vs RandomizedSearch', fontsize=15)
plt.ylabel('F1-Score', fontsize=12)
plt.xlabel('Damage Level', fontsize=12)
plt.ylim(0.4, 0.8)  # Adjust upper limit to center visualization
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.legend(title='Optimization Approach')

# Add value labels above the bars
for i, row in enumerate(class_comparison.itertuples()):
    plt.text(i % 3 - 0.2 + (i // 3) * 0.4, row.F1_Score + 0.01, f'{row.F1_Score:.3f}',
             ha='center', fontsize=9, fontweight='bold')

plt.tight_layout()
plt.show()

"""## RandomizedSearchCV on best model"""

# Ensure the best model name is defined
if 'best_model_name' not in globals():
    raise ValueError("The 'best_model_name' variable is not defined.")

print(f"Starting final optimization for the best model: {best_model_name}")

# Define parameters based on the best model selected
if best_model_name == 'LGBMClassifier':
    model_class = LGBMClassifier
    final_param_dist = {
        'n_estimators': [200, 300, 500, 700],
        'learning_rate': [0.01, 0.03, 0.05, 0.07],
        'max_depth': [7, 9, 11, 15],
        'num_leaves': [31, 63, 127],
        'min_child_samples': [10, 20, 30],
        'subsample': [0.7, 0.8, 0.9],
        'colsample_bytree': [0.7, 0.8, 0.9],
        'reg_alpha': [0, 0.1, 0.5],
        'reg_lambda': [0, 0.1, 0.5]
    }
    base_params = {'random_state': 42, 'n_jobs': -1}

elif best_model_name == 'BaggingClassifier':
    model_class = BaggingClassifier
    base_est_params = {
        'max_depth': [10, 20, 30, None],
        'min_samples_split': [2, 3, 5],
        'min_samples_leaf': [1, 2, 4]
    }
    final_param_dist = {
        'n_estimators': [50, 100, 200, 300],
        'max_samples': [0.5, 0.7, 0.8, 1.0],
        'max_features': [0.5, 0.7, 0.8, 1.0],
        'bootstrap': [True, False]
    }
    # Add base estimator parameters to final param distribution
    for param, values in base_est_params.items():
        final_param_dist[f'base_estimator__{param}'] = values
    base_params = {'base_estimator': DecisionTreeClassifier(random_state=42), 'random_state': 42, 'n_jobs': -1}

elif best_model_name == 'RandomForest':
    model_class = RandomForestClassifier
    final_param_dist = {
        'n_estimators': [200, 300, 400, 500],
        'max_depth': [15, 20, 30, None],
        'min_samples_split': [2, 3, 5, 7],
        'min_samples_leaf': [1, 2, 3, 4],
        'max_features': ['sqrt', 'log2'],
        'bootstrap': [True, False],
        'class_weight': [None, 'balanced', 'balanced_subsample']
    }
    base_params = {'random_state': 42, 'n_jobs': -1}

else:  # For SVM
    model_class = SVC
    final_param_dist = {
        'C': [0.1, 0.5, 1, 5, 10],
        'kernel': ['linear', 'rbf', 'poly'],
        'gamma': ['scale', 'auto', 0.01, 0.1, 1],
        'class_weight': [None, 'balanced']
    }
    base_params = {'probability': True, 'random_state': 42}

# Split 20% of the data for training
X_train_final, X_unused, y_train_final, y_unused = train_test_split(
    X_train_processed, y_train, test_size=0.8, stratify=y_train, random_state=42
)

# 3-fold cross-validation within the 20% training set
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

print(f"Using only 20% ({len(X_train_final)} samples) for training and validating on 1/3 of this set.")

# Generate parameter combinations for hyperparameter tuning
param_list = list(ParameterSampler(final_param_dist, n_iter=30, random_state=42))

best_score_final = 0
best_params_final = None

print(f"Starting final optimization for {best_model_name} with {len(param_list)} combinations...")
# Perform the search across the parameters
for params in tqdm(param_list, desc=f"Optimizing {best_model_name}"):
    model = model_class(**base_params, **params)
    scores = []
    # Cross-validation loop
    for train_idx, val_idx in cv.split(X_train_final, y_train_final):
        X_fold_train = X_train_final.iloc[train_idx] if hasattr(X_train_final, 'iloc') else X_train_final[train_idx]
        X_fold_val = X_train_final.iloc[val_idx] if hasattr(X_train_final, 'iloc') else X_train_final[val_idx]
        y_fold_train = y_train_final.iloc[train_idx] if hasattr(y_train_final, 'iloc') else y_train_final[train_idx]
        y_fold_val = y_train_final.iloc[val_idx] if hasattr(y_train_final, 'iloc') else y_train_final[val_idx]

        # Train model and evaluate
        model.fit(X_fold_train, y_fold_train)
        y_pred = model.predict(X_fold_val)
        scores.append(f1_score(y_fold_val, y_pred, average='micro'))

    mean_score = np.mean(scores)
    if mean_score > best_score_final:
        best_score_final = mean_score
        best_params_final = params
        print(f"\nNew best F1-score: {best_score_final:.4f} with parameters: {params}")

# Train final model with the 20% of data
final_model = model_class(**base_params, **best_params_final)
final_model.fit(X_train_final, y_train_final)

print(f"Best F1-score from cross-validation: {best_score_final:.4f}")
y_pred_final = final_model.predict(X_test_processed)

final_f1 = f1_score(y_test, y_pred_final, average='micro')
print(f"Final F1-score on test set: {final_f1:.4f}")

# Plot confusion matrix
plt.figure(figsize=(10, 8))
conf_matrix = confusion_matrix(y_test, y_pred_final)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.title(f'Final Confusion Matrix - {best_model_name}', fontsize=15)
plt.ylabel('True Class', fontsize=12)
plt.xlabel('Predicted Class', fontsize=12)
plt.tight_layout()
plt.show()

# Print detailed classification report
print(classification_report(y_test, y_pred_final))

# Save the trained model
if not os.path.exists("models"):
    os.makedirs("models")
model_path = os.path.join("models", "final_optimized_model.pkl")
with open(model_path, 'wb') as file:
    pickle.dump(final_model, file)

print(f"Model saved at {model_path}")

"""## Prediction and csv"""

# Check if we are in Google Colab to enable file download
try:
    from google.colab import files
    is_colab = True  # If in Google Colab, set flag to True
except ImportError:
    is_colab = False  # If not in Colab, set flag to False

# Print current date and time, and user information
print(f"Current date and time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"Current user: Saultr21")
print("\n=== GENERATING PREDICTIONS FOR SUBMISSION ===\n")

# Load the final optimized model (or use the one already in memory)
try:
    with open('final_optimized_model.pkl', 'rb') as file:
        final_model = pickle.load(file)  # Load model from file
    print("Final model loaded successfully")
except:
    print("Using the final model already in memory")

# Load test data for predictions
test_values_url = "https://raw.githubusercontent.com/AdrianYArmas/IaBigData/refs/heads/main/SNS/3%20%20-%20Algoritmos%20y%20herramientas%20para%20el%20aprendizaje%20supervisado%20/3.7%20%20Predicci%C3%B3n%20de%20Riesgo%20de%20derrumbamiento_Terremotos/dataset/test_values.csv"
test_values = pd.read_csv(test_values_url)  # Read test data from URL
print(f"Test data loaded: {test_values.shape} records")

# Save the building IDs for submission
test_building_ids = test_values['building_id'].values

# Preprocess the test data before making predictions
print("Preprocessing test data...")
X_test_submission = preprocessor.transform(test_values)  # Assuming preprocessor is already defined
print(f"Test data preprocessed successfully")

# Generate predictions (with progress bar for large files)
print("Generating predictions...")
test_predictions = final_model.predict(X_test_submission)  # Use model to predict
print(f"Predictions generated for {len(test_predictions)} buildings")

# Create a DataFrame for submission
submission_df = pd.DataFrame({
    'building_id': test_building_ids,  # Use building IDs from the test data
    'damage_grade': test_predictions  # Predicted damage grades
})

# Verify the submission file is saved correctly
submission_file = 'submission.csv'
submission_df.to_csv(submission_file, index=False)  # Save DataFrame to CSV
print(f"Submission file generated: {submission_file}")

# Check if the file exists after saving
if os.path.exists(submission_file):
    print(f"The file '{submission_file}' has been saved successfully.")
else:
    print(f"There was an issue saving the file '{submission_file}'.")

# If running in Google Colab, allow the user to download the file
if is_colab:
    files.download(submission_file)  # Enable download in Colab

# Show the first few rows of the submission file
print("\nFirst rows of the submission file:")
display(submission_df.head(10))

# Plot the distribution of predicted damage grades
plt.figure(figsize=(10, 6))
sns.countplot(x=submission_df['damage_grade'], palette=['lightgreen', 'orange', 'red'])
plt.title('Distribution of Predicted Damage Grades', fontsize=15)
plt.xlabel('Damage Level', fontsize=12)
plt.ylabel('Number of Buildings', fontsize=12)
plt.xticks([0, 1, 2], ['Low (1)', 'Medium (2)', 'High (3)'])

# Add values above the bars for counts and percentages
counts = submission_df['damage_grade'].value_counts().sort_index()
for i, count in enumerate(counts):
    plt.text(i, count + 100, f"{count} ({count/len(submission_df)*100:.1f}%)",
             ha='center', fontsize=10)

plt.tight_layout()
plt.show()  # Display the plot

"""# Tests & versions

## Test 1
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest, f_classif
from lazypredict.Supervised import LazyClassifier

# Cargar datos
path = '/content/Earthquake_dataset/Earthquake_dataset/'
train_features = pd.read_csv(path + 'train_values.csv')
train_labels = pd.read_csv(path + 'train_labels.csv')
test_features = pd.read_csv(path + 'test_values.csv')

# Eliminar columnas irrelevantes
X = train_features.drop(['building_id'], axis=1)
y = train_labels['damage_grade']

# Convertir variables categóricas en numéricas
X_encoded = pd.get_dummies(X, drop_first=True)

# Selección de características
selector = SelectKBest(score_func=f_classif, k=10)  # Cambiar k según sea necesario
X_best = selector.fit_transform(X_encoded, y)

# Dividir datos en entrenamiento y prueba
X_train, X_test, Y_train, Y_test = train_test_split(
    X_best, y, test_size=0.3, random_state=100
)

# LazyPredict
clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)
models, predictions = clf.fit(X_train, X_test, Y_train, Y_test)

# Mostrar resultados
print(models)

"""![image.png](data:image/png;base64,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)

![image.png](data:image/png;base64,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)
"""