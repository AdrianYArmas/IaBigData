# -*- coding: utf-8 -*-
"""SNS_ACT3_4_AdriánYaredArmasdelaNuez.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11UKuve9EnyARvEpWsS8kUjgYlOx1qWGx

**Adrián Yared Armas de la Nuez**

## Origen y explicación del dataset Titanic

El dataset Titanic proviene de los registros de pasajeros del RMS Titanic, el transatlántico que se hundió en 1912. Contiene información sobre los pasajeros, como su clase de boleto, sexo, edad, número de familiares a bordo, tarifa del pasaje y si sobrevivieron. Las características incluyen: survived (si el pasajero sobrevivió o no), pclass (clase del boleto), sex (sexo), age (edad), sibsp (número de hermanos/cónyuges), parch (número de padres/hijos), fare (tarifa), embarked (puerto de embarque), who (género) y alone (viajaba solo o acompañado). Este conjunto de datos es comúnmente utilizado en el aprendizaje de técnicas de modelado predictivo y análisis exploratorio, ayudando a comprender cómo diversas variables influyeron en la supervivencia de los pasajeros.

## Reflexión sobre la elección de características

Elegí variables relevantes para predecir la supervivencia en el Titanic. La clase del boleto (Pclass) es importante, ya que los pasajeros de primera clase tuvieron mayores probabilidades de sobrevivir. El sexo también influyó, con una mayor tasa de supervivencia entre las mujeres. La edad es relevante, ya que niños y personas mayores fueron rescatados con más frecuencia. El número de hermanos y/o cónyuges (Sibsp) a bordo podría haber afectado las oportunidades de evacuación, mientras que la tarifa del pasaje (Fare) se relaciona con la clase social y las probabilidades de sobrevivir. Estas características, aunque no exhaustivas, cubren varias dimensiones clave que influyeron en la supervivencia.

## Test todos los modelos

### Imports
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB
from sklearn.metrics import accuracy_score

"""### Dataset Load"""

# Cargar el dataset Titanic de Seaborn
data = sns.load_dataset('titanic')

"""### Data processing"""

# Eliminar columnas con demasiados valores faltantes
threshold = 0.4  # Porcentaje mínimo de valores no nulos requeridos
cols_to_keep = data.columns[data.isnull().mean() < (1 - threshold)]
data = data[cols_to_keep]

# Llenar valores faltantes
for col in data.columns:
    if data[col].dtype == 'object' or data[col].dtype.name == 'category':
        # Si es categórico, llenamos con la moda
        data[col] = data[col].fillna(data[col].mode()[0])
    else:
        # Si es numérico, llenamos con la media
        data[col] = data[col].fillna(data[col].mean())

# Conversión de variables categóricas
label_encoders = {}
for col in data.select_dtypes(include='object').columns:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le

# Separar características y la variable objetivo
target = 'survived'
X = data.drop(columns=[target])
y = data[target]

# Escalado de datos
numeric_columns = X.select_dtypes(include=['float64', 'int64']).columns
categorical_columns = X.select_dtypes(include=['object', 'category']).columns

scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X[numeric_columns]), columns=numeric_columns)
X_categorical = X[categorical_columns]

# Combinar datos escalados y categóricos
X = pd.concat([X_scaled, X_categorical.reset_index(drop=True)], axis=1)

"""### Data selection

#### Correlation graph
"""

# 3.1 Matriz de gráficos de correlación
plt.figure(figsize=(10, 8))
numeric_columns = X.select_dtypes(include=['float64', 'int64']).columns
X_numeric = X[numeric_columns]
correlation_matrix = X_numeric.corr()
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')
plt.title('Matriz de correlación')
plt.show()

"""#### Dispersion matrix Graph"""

sns.pairplot(pd.concat([X_numeric, y], axis=1), diag_kind='kde', hue=target)
plt.show()

"""#### SelectKBest"""

k = 5  # Seleccionar las 5 mejores características
skb = SelectKBest(score_func=chi2, k=k)
X_selected = skb.fit_transform(abs(X_numeric), y)
selected_features = X_numeric.columns[skb.get_support()]
print(f"Características seleccionadas: {selected_features.tolist()}")

"""### Train and test data split"""

X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

"""### Naive bayes model train"""

# Sin Cross Validation
def train_and_evaluate(model, X_train, X_test, y_train, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)

models = {
    'GaussianNB': GaussianNB(),
    'MultinomialNB': MultinomialNB(),
    'ComplementNB': ComplementNB(),
    'BernoulliNB': BernoulliNB(),
    'CategoricalNB': CategoricalNB()
}

print("Resultados sin Cross Validation:")
results_no_cv = {}
for name, model in models.items():
    try:
        acc = train_and_evaluate(model, X_train, X_test, y_train, y_test)
        results_no_cv[name] = acc
        print(f"{name}: {acc:.2f}")
    except Exception as e:
        print(f"{name}: Error ({e})")

# Con Cross Validation
print("\nResultados con Cross Validation:")
results_cv = {}
for name, model in models.items():
    try:
        scores = cross_val_score(model, X_selected, y, cv=5, scoring='accuracy')
        results_cv[name] = scores.mean()
        print(f"{name}: {scores.mean():.2f}")
    except Exception as e:
        print(f"{name}: Error ({e})")

"""### Result compare"""

print("\nComparación de resultados:")
comparison = pd.DataFrame({"Sin Cross Validation": results_no_cv, "Con Cross Validation": results_cv})
print(comparison)

"""## Selección de los mejores modelos y mejora de precisión

### Imports
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.naive_bayes import GaussianNB, BernoulliNB
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score

"""### Dataset Load"""

#dataset Titanic de Seaborn
data = sns.load_dataset('titanic')

"""### Data preprocessing"""

# Eliminar columnas con demasiados valores faltantes
threshold = 0.4  # Porcentaje mínimo de valores no nulos requeridos
cols_to_keep = data.columns[data.isnull().mean() < (1 - threshold)]
data = data[cols_to_keep]

# Llenar valores faltantes
for col in data.columns:
    if data[col].dtype == 'object' or data[col].dtype.name == 'category':
        # Si es categórico, llenamos con la moda
        data[col] = data[col].fillna(data[col].mode()[0])
    else:
        # Si es numérico, llenamos con la media
        data[col] = data[col].fillna(data[col].mean())

# Conversión de variables categóricas
label_encoders = {}
for col in data.select_dtypes(include='object').columns:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le

# Separar características y la variable objetivo
target = 'survived'
X = data.drop(columns=[target])
y = data[target]

# Escalado de datos
numeric_columns = X.select_dtypes(include=['float64', 'int64']).columns
categorical_columns = X.select_dtypes(include=['object', 'category']).columns

scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X[numeric_columns]), columns=numeric_columns)
X_categorical = X[categorical_columns]

# Combinar datos escalados y categóricos
X = pd.concat([X_scaled, X_categorical.reset_index(drop=True)], axis=1)

"""### Data selection

#### Correlation matrix
"""

# 3.1 Matriz de gráficos de correlación
plt.figure(figsize=(10, 8))
numeric_columns = X.select_dtypes(include=['float64', 'int64']).columns
X_numeric = X[numeric_columns]
correlation_matrix = X_numeric.corr()
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')
plt.title('Matriz de correlación')
plt.show()

"""#### Dispersion matrix"""

# 3.2 Matriz de gráficos de dispersión
print(f'Matriz de Dispersión: ')
sns.pairplot(pd.concat([X_numeric, y], axis=1), diag_kind='kde', hue=target)
plt.show()

"""#### SelectKBest"""

# 3.3 SelectKBest
k = 5  # Seleccionar las 5 mejores características
skb = SelectKBest(score_func=chi2, k=k)
X_selected = skb.fit_transform(abs(X_numeric), y)
selected_features = X_numeric.columns[skb.get_support()]
print(f"Características seleccionadas (SelectKBest): {selected_features.tolist()}")

"""### Dimentional reduction"""

# 4. Reducción de dimensionalidad con PCA
pca = PCA(n_components=0.95)  # Retener el 95% de la varianza
X_reduced = pca.fit_transform(X_selected)

"""### Data split Train and test"""

# 5. División del conjunto de datos
X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)

"""### Naive bayes trainning"""

# Entrenamiento de modelos Naive Bayes (GaussianNB y BernoulliNB)
# Función para entrenar y evaluar el modelo
def train_and_evaluate(model, X_train, X_test, y_train, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)

# Modelos seleccionados: GaussianNB y BernoulliNB
models = {
    'GaussianNB': GaussianNB(),
    'BernoulliNB': BernoulliNB()
}

# Evaluar sin Cross Validation
print("Resultados sin Cross Validation:")
results_no_cv = {}
for name, model in models.items():
    try:
        acc = train_and_evaluate(model, X_train, X_test, y_train, y_test)
        results_no_cv[name] = acc
        print(f"{name}: {acc:.2f}")
    except Exception as e:
        print(f"{name}: Error ({e})")

# Evaluar con Cross Validation (CV=10 para mayor robustez)
print("\nResultados con Cross Validation:")
results_cv = {}
for name, model in models.items():
    try:
        scores = cross_val_score(model, X_reduced, y, cv=10, scoring='accuracy')
        results_cv[name] = scores.mean()
        print(f"{name}: {scores.mean():.2f}")
    except Exception as e:
        print(f"{name}: Error ({e})")

"""### Result comparation"""

# Comparación de resultados
print("\nComparación de resultados:")
comparison = pd.DataFrame({
    "Sin Cross Validation": results_no_cv,
    "Con Cross Validation": results_cv
})
print(comparison)

"""## Conclusión sobre los resultados obtenidos en la predicción y evaluación

![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfkAAABOCAYAAAAjDm+dAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAABpfSURBVHhe7Z09TxxJt8fPveFkg0Tk0QZGIjKB9QRL6tGGSwYpxDjCX2At+wvYkYkhhQyHq3GKg0cOIELCgTWOLDHZpPeeUy/dp6qrq7uHGWDG/99qtGZ6urq6uk6dl6qu8z/b29v/RwAAAABYOf7X/R8AAAAAKwaUPAAAALCiQMln2Hl7QmdnZ/ThtfsixesP5jdnHw/dF3NGyj/5h3bcn0vL3//QibST+XygBbWWZVXaDAAA7kk7Je8Vmfmc0D9/u+9/d6RdXq3R1cke7R0duy9Bks/v6WCP2+nkiqbuq5jDj2d08haqGQAA5kWjkjferFdkMkjvnRP99Xt4SRfvDsw9v/nkvoj59IaPH9D7z+5vAAAA4AnRsLr+kD6cDYm+ZBSdhGEPtqjn/qSfI+fV7tA/J7tE3+9o68XAfD+iIQ2fEY1Nee742SX1D4bEv2DGNNp7Q6VPbK9vjzFF2Yy5bp8u925o0/9mekWnB+/pwvzAGij7L3zNpmyoRArZeOJF6TS9PqWDd3K2vm7iPEa8TrkXi/5Nm/vKE9abCe5Lyt+nLX9Yt0kTndus4Xnoc6Ut/5yosuS32zSJ266oQ1lu5X49wb1l+gKTb7NMvQ1Nx335lOwLAADwVMl78q83eeAb002dgpfBkRX8HStt6+WPaPxsqEKuPdp6zgO/hGj5++3JKZ1eT2mw6Wdk+fiBKAJ7/ujngIZqbvvw4ybdmHLLssP5cf69USTueG+Lhv44K5Mhnbtz9/i6RFt7KgKhQ+3uN1bBC8f0xl/TfaORAX/YZ0Wgyz7Q88z6vk7pajqg7bZhaK7X/os7Vq6uXl/CGhx+ZAU/YQVnjnPZfd3ebci0WXTt0+s1Gqq57cOPQ1pjQ8hemz+RIpwVHzEZ/WT9qstXSjzbF7JtJkaRrje3GW3RftDPFnNfAADw2Nxr4d3O220asNczKowAVo48wPaevywUw/irHzDHdFko0ZLxl9IzOr7hwbm/Xpx7fKS9yGO6YSWwth4qtPL86Pjn9/RGXe/iv7c07fWdt8YD/58DVijnM3hlhzRkj7G8L1FS50aRbyoDpKzXBX37PqVev/ATM9h6jb/Uef2HtPmMvetC+V3Q+69he7ehrs0ON8NrX7y7ZCNgg16qNRhdrzUv6vtCQ5u9HtJWT/c9brMzMTo3lVHWfF/WEIEXDwBYLu6/un7yq1B2c6FQxIx428WCPx0e94RRhuMj7Y2LB1eee6anFPgKff7j7tesNZ/S5If750Py9zqtGU9c3ZeabmhHXZvt0HqfW+aVKluHsJnjI+cFu+PZtw7mTWNfyDCdJCMynke9LwAAWCB5Jf9jwuos9FArKM9b2Flfc/+aET8gy9wtKzCZv/dhVAnntsWEtXno9iH1cFX3mCZ1S7xb0aP+H+6fBms0PAwyT162ifnMMbys29t+tPfKXvCB+57bc40NggdRiPfsC4HhKPzRVwaf8Ej3BQAACyav5D+/p0seTAev9Hwze8gf7TytDYGrOd1EKLs9h/SBB/Lp92/qXOUxsyfXyXsTiigD13lPe/I2hB7eV1tsqHjwZzlXXZ22mJUL+jXhsv2aBafcCj5/o9vpIFi3MD86tsnnX3Tn/lmgp0NOwihAG8ZsedWHzev6QkObfbphs0ivibDh/en1KB3eT90XI+sw8PooAGDZaLV3ff1KckYGVRUKL1eoy0C/T/2ve/Tmh/zGrqgeyyrl/iXtHY3DVeJMea4luC4r0avJFm1M3G/MdcNV2gFRvcbX7KG9yK/qLq4voWGtKAzhfYdtolehq/t2St9cx9xzsqYReqU3l3syoe09ovPCW7fl59qtlqY2Y+I2KVeaRyvQmdzzGn8ZEb0qV9dXyjXEq/eje1Mr6LN9obHNorrnVu0zqfa09cfqegDAcvGICWqqyhAAAAAA8+P+C+8AAAAA8CSBkgcAAABWFOSTBwAAAFYUePIAAADAigIlDwAAAKwoUPIAAADAigIlv4rI+/CyRetCNs353ZD36P12uvWb4ch7/M2b5chro/PeTc/VTyUSAr8ftv/ZT13CKtnrodW2zbJPyJz7Uzv5WCALuKdFIu01r3ECSn7p0ErHfh5yC1Y/UNjPLDsGPiRWqaYGPRGidtn78hkJF86SDU4ltu2LvvKgBmcoI92yND4C8oxTsmSM9XYyJjkoOm/3PC861PNRkPpJxtGz6k6syfFsDs/DkHO2zDX8davGz/G/sr32fIwiKPmlQgbOKC0qfyqbCX1+TwdyrNUOe+0RxRikdJW89E86WuAyAFa2ypVsflO6/W8s8rNjB9nH2A3PGSFPKj2uKFmdEpk/N5sPY4yagTWUkXMaPp4H2Qa39XKcI2TnPxvU+3lTuztlV3xK58fYfOzx5IPHzL0tokTG0drxbA7PwxgPe0S3KaPLGx0uzXk1VTkjY/iXuzA9+ozgFbplQjrHwQbdZrZWlY7rt3+tbM8q1uPmDZ1OtostZrttiZu5tjkuW+ayoPhtYostcS26bnww2iJWDBi9XW+85a0oDrX9bFR2Lal6Szv8OVHnR2UH29565DflNr0Fpny/fXJcZyEqm5FEO8VAK3VRWygXx4JyNeU17Fa77heJOgfHGX1dObbL6u+yv6+2Ip6PAjDXfX6beT65ZynHNulGtib299/2WTOmj1Hq+Vnk+PbklO98t2ibuF3q2kzIH2/qw/VU623LKncEjcquaRN/f6FM6/aO5c4S31f1maTko9q3LeoaXeVjjn3BUJF1R2pcUDQ/jwxS9l+/6IDPTfXH6ne2Dagifx2umQGe/DJhEtT02OqrD+M0hu2eDe0++mK5Su7/F0PuYs0YK3Z6S98SAlEyoKFRhFKHEY1V8iIZRIZ9FlBnNcfW687b3dDziwaDw49RBKOtoLs22/hPaQ9L3nydCOnwIw8kxXW53txGrb1OHzUJshx6REh1vU/pKvgRCzcbXcU98fMoEgT5cvk7M7D536h28Z7Z6XUipSIPboGXYsoO+03vxb5RCL4MnXRpdnbo5fNelGhKk2gTSfMbRIQGNDQGoxwP+1EeidCwKrnRPaeK3LeXgeC+m9qMB+/dwPMLB9+mPpzj+Iaf87PNUhb/fkkbvTIt9M5bVgLsGtpybZvttp6GaJhySty3pl4+XLmm74sC979RirOrfMytL1hiWfc0jWdNzyOL3LNS6iE2pXfZR20biJGzth4/T5c0zCffmhEo+aXCpkS1CtLO53SebxSF4TugCUut0focQ5njL17AbbY+23Gr2Qkv3p2zwotCYlqoEtRnqMsRh+yrofrjIz0Y63rfk9dDk+74vDZSwoOkHgzm9jx44Igz7X16w4ZfaOyIR+Y9PptRMkrJuwikTXiwvCzahPv0GSuA4NmLJ+ifyRyfh0fJQHnfLduMf5lNvd3Qh2uJQsRxaPji3Rvlcbo+3Z/H07L3Pf5Sb5AsVD4W2hesQr37VSd/GRqeh3jj5Zy6/3SbQ7dl7NPG91NjbKae58Wvu0o6965AyS8h3oMT65jYK3k6q+hDS1eiCmXYUKWKTSD3NPo5oKETmNh4OT5yVr473mV+1w7kG/RSBPD1Jg1iC15Ceq5c+ZRTCosnHCxSoc/ZmWlwewimE+4pj0fg2RlPs1Ri2TaT3xrv3j2vaEFkUx/OYxWY9dpsNCSISEgIuOgnMpesQuuLZpHysdC+MKD+zM2Ufx4+Yhp+0qH/FNKHfBRNxsgBV3Q6SbTEj8m9jW8o+WWGB51zCdXe09Jrg7EovaKciR71/3D/NFQFsBScEd2x8RIOkjaKYY6zcbPGQtI+pF6G7CvhOxk8X4kn46/9cCuUzRTGMx3mrAmnzkjo8VivZvHY/P7ZqEs8aP3RT6w9mIUxTVgc7hPebGwz9u6LfjJhozNS9Pk+nKcIEVdCw4f04UAWj/mwds0UzSJYtHwsrC8Itj+kaDOe1T+P+3jyVj50FM33s6SBKe1xT0MISn6psRYmTX6VSmtRfBrRlawHCFZ78uDTKorgrGI157vzdps96isaJee46oXT8PkXsYh2wIfsd2k7uapeRRnYa5mbp2Ks8HIgOfyoF2U5lADLuoOKxR6V0Q53v3q9RSU0ujjk9Z9pL5oz5nY1RpkLg24XxxJh8plhQ/CrDMzhmoqdtx9aDb5d22yc7aQNfTiFb5u99CruQgmYtQHzUoVW6RSGkVPqIQ3yYeSxYRojxUL7gmDvLRnebzOeZZ7HfTx5azyoPur6WWq+f2d97d7jO1bXLxMSNosFMFhVbVdpVkSUPQBjNcr5lVXliRXjtbAQ1q0elsHBLJCpn9szq0qLAUKvtI3LZRruq/VbAR5Tvy22iqurc4N68fEr9tA2/ArlVJubeULbZpVVyYby3vRxqbOsZt+88Qu2wvuaXl+x97dReR7hNXzZiTYTVLuF54Wrqs0xWXzm27jF8+uEb2/3Z/Z5Vo6FfVKeT3XFeIbomem+0lRWY5sFz7pLH26H74v5Vf1jurpeo63i+VXlQwjkPtOHw/P5nmQ1+x7RuZOTrHx4gmu0l49K3RfSF0hdT5MZzxx1zyNP+nkE9xa0V/W6Flu/+66uh5IHAACwolhFKYvbWhsGTwUxBFKv/3UE4XoAAAAril2xTy92O618f3TMtEl6l76uQMkDAABYXcxbEfPZPe6hOPxri+6K15HvB8L1AAAAwIoCTx4AAABYUaDkAQAAgBUFSh4AAABYUZZeyct7mLLbUJdtTgEAAIDfgVYL73IbRDw2vm7dNivIYzdA0PcZbkoQbA5hqNvMAKwENRt9NBKcp1CbYsSbnNRtxuEJ+3m86UZ4frwRSbCBUFy3GTZuAeCxaZKfLPGGTfFGWQ1y30U2w827EpvlBNeONum5p2w2evJyI2Fi/XOiv57Oqwg+WUvZuPNhOqUo+1SENLxrE5OU4skkiQFzxb+vatLn+gyAZYrcLGqfc/uxqWaLRBQ8iGjZOr1eo6HaC10GMJN32p9vkqP4a8tAYHNQ++NBP5SyJae7P9ckM1LvCgd143r1h90zGgLwmETyY/p/lEugHla0Jp+8kgGdvrdB7tvIZpFC1yUSC6PNYpC4c+WjjAtJWSyb99hjNrXvfWQzr+T5RmWv7zLVn3BB74/0C/pilahN+rWyE0soaHT5rd7EXxpDnXsWD55R2ZWy/LF0YgB5EGXZ8XXlb11GdO3vt3TXMte62Yv4AZLEgIdH3lft/bwsLPiLd5csnjPs0y24RBd2L3Tug9E+3aZstU99JTOV7GPv/mkT/ISZ/fRe6pU9r7P7/bukGQAsDVX5sTkTWuZ5+Hud1lgifhWeeSgDTXKflc0458Hn93RZZLRrRhzX0uu3eT/uk1Y4q+SbEusLhx836aawSKzV0XZ+XCyWrYmyhiqhSmUNySfY3u+Y3vhrum8C2EAZ0nlxrrHEgs0QemyZyb7Iclw8LJ0oQfhGI/as2gzmlcxmYEWw2aHKFJPWQhdxmyWftgwcFCXfCDNPSVKTMlufGI+9wgPga+/JwOMTZYjwSx92xin3d0la4utq0usqD8Akv6mV5WqOfQCeNtbILfssO2wm9B5nu6zBZKYclJ4/O6QyRWvLa5b7nGwaA1sltDFev4T1H8kRbL/wTsIX3utVHvXxkVbM1uroNABKKj/3zxTZlJU52Hp6U1hDbtCL0hqOix2FXAaqyFqSc9ZU5rQAHkB9lGDYv6JzdS2wesi01dmZ3QNb0nx2tqxNVExnNLN9LszMx0ZvOYXuQuojIpO/3F5bz82ZTFhfyOYvd6HHYtpKdvli4/X2+b7toxJajPbALiNdPIAprwWA5UEUsO3DMnUlaXDb6R+buvr0+wbtiwyYJDbVtTa1ct8gmwaJZHPZZtrsRKIMWv8MrNyaTyZFrTM+rv6Nyu5AeyVvBg0ZVCK/2d2I/4QL0vJIWMLMo7hz43mH4yM7T2IeAn+6raD3D9999AKLtkiYZVIT/lFz8rajxFMNYFUYsCBL5it51hJGq4TqWmDDf2G6yot350H/3qVLupqGaT3PTBYu6Wc2P7k2sM0AJAksjFzesVevZMgY5XaxqJ9zj6ek/HoW04cn29F0GABPHYlk+T4uBm4mL3sFqx9MJkbp/7IeJtIxWblvkE3jBHrZFOM6yAvvo9DuY2Q3oehFhl9JLv+WC31ryCr5xsT6RSXKCosl1YUyL69tqFDRW2vLHGdLaI0bva2iN7m7eQjVC4/KGcv2HN/wA/jrpfsrjZ2vWaP1NnNBYIlw83Rs0JVzZF0GEofx4lPWuOrf/Dl4R9Tv+XlCHoTMnOO5E3AZGEY07m3RUGTAl+kTWIhnwQa4z4dujYqR8+zlOqkpqZJUpAuAp4vN1y+r1stF19V1KrW4efOR877F4BVP3UbWmuQ+L5tGb3L9RnoxXS4vvMlbHyG6lR1TCu5vNvKefDKxfkzoeVQ8+WLgEMspem0gwD60WrILh2ooGpWvLXMm5t8dkTbob9CG+zPFztvtzHwnWGbMokq9zsQNDjeB4FmvoC7sFi/iSSOLQCXkGK5LCaYFXm+y/OhBLJx/lLUh7GqUA4aeAzSL/uqNk1SkAYCni5tiVW+MJMdhUZYSKUtGqbRjtkMvn7OAOJ3RRu5rZdMo7YF64+qQhmq9TExlvYxS8KWRMTut3pOP3wfU7/QFx/j7q8kWbaik/vr4+IvMYUiIQ8IPMjDqhP2MhMCLeQ076GmjIPuer0G9y+gayhc/vr6itRd9ujSL++y1dTJ+mZ80oRu+vtRZwjT+WuaYPCT3HmSlPcRq6/J+Jlgugr6Weta+L6v+5zHnyqs4iZBbUG7i3IoMRL+JZSD3ri2j3+P1fbogkD0AloOgH8fvuQteDySONcpAVu4bZDM6HrxDH8ttdN2qfhFS40M7kIUOAAAAWFHaL7wDAAAAwFIBJQ8AAACsKFDyAAAAwIoCJQ8AAACsKFDyAAAAwIoCJQ8AAACsKFDyAAAAwIqyuu/JB5vhVDcwCTZCqNkIJN4EBwAAAFgmGpR8dde5pdsZyyh7v9NdFaPI3U53MWkl73cS04aDtJPfyW8F2gyENO5MV0O8s5VH9Yd4161yV8fEjpAGd30Kd3Qs0Dt7NdQ73q2yslsYAE+cUH467DzaWTajsjvvWhfJXxfZZO7jaLYK18sFfBKZLvnilx2fpSvVuNNpPtf879pmK4cYiWZbWvs8T6+pzOHehElH6fuBfCRJDPcdlcnKpKH0x0+uiIq9uMPkNeZjMkC6BDY+K6T6mORQPl9DQ71lAJMUyf7ao8kW7Rd7bQOwBIj8vLhj5ev7/6DMD99EG9lUZZssdbrs4Hyb5THOolrqAPkoJd5GNiU1tD+X5X7wavYspx3n5FP54sVztaky5RPcqNyMSW+pflM0lHgqktBDnx/diDnfH+OPHoTEEgoeqJSTycvbCV2ndJl33zO55gNmyLEPngxxchmbcXCQNfBqMUliypzylcxUDUmYJAHN9HpU46kc0qbKdJevt0uY8bX03I//vaLps81Q/gB4srD+MJngSnkwfTiXNTVHIJvVso381Jbtsta1pGlMqaSy/jFhX392Oip5O5Dc/tcPDaKoh7R2bXPu+nSxodc6oKHKu1ukyjRIPmB/LE6FyYr2YIvuIo84tpYWg8/3y9d031T4lck1HxC3GVgebHrJMnuU7e8SZJvFaBPhJj1wSHpX1acr2ag0bPBuPysNhBiTgasYONrUO0rJaQwMpEsGy4JNK1uOq1Zf9Pg/nZmxLbFsCmHGRsmSWld2lzG+WTYlA16v0KN8XDKo3iNDZCslL8nzrVcrCt3n0GXE+qErOi8GnmMaSU7ezdAfKJPeV73a8phLHejS99m0gVc0KkLlrHglX/bzl3zbTwObaz7t+9S2GVhKZI7s7GyfNr6fmrzTQZrJNqSUtAm5n9Lt833TV0yIrmZePDUIlYhnTol89XX1FjlkA1v1XWNguH8DsDyIkrTjLLFDKFNWnQ3wimxaXWRzy1t23u5W1sdIWN2P8aWBXVLqgCjC7agdU8xUgGRsLY/fZ01Xxzl5NyD5sPkffeqxZ77vbkQ+ehGRJczBe3y0V6aLbaIuyf5TweSaT4c4a9sMLB0irJJ6WJ6n9N1KOK0FNkQXWeNmOsqmPPbzepUpK8EMQvWeQjKPNpOr9/GRjYx5ud28kaiVm+8HYCmQSLCXH1k7Zb3k0ANvJiWbF+/O2X0tddsuXdLVNIx++TVb8jmdbAfTx6Ln/DEf4daKPjumyFS0in7Luel8+O3oGK6/oPdfuSL99fKCsiq3uBn3mddKcn0dxsxhPinE4luj7bfr7u8UiTYDS4Kba/s5UobpDAOJU9Kxp20Hl5Fb2CkL7eIpK4v9XdVTsFTn19vV209J2c+bH+u0Np3UT08B8KSQ8Dmrn+tTtTDahvCDaagmamTTymMpHwfveAjv1RvBZuqt16+JhtkItqVJNnfcegAf/RU5jae5u9FRybsKfP9mB5RPN+biuwuYJ7eNpm8sMZgVjVrOazw0smji7vkG1ZsfUZuBpULmx0i/HfF6aF6f1NEp2//E4k8v0swqaW38mcU/kQFROwhZqtNalnb1dkhE4WCDbs/wCh1YFtz0bvE2ipeFKKIlfVu88RpPOG9Ae2QhtkwH1L+el4oGFLBnPlSRuDayGUwHvt5k3dbReFHM4T356m8kVG2sKzN41L2jLgOjDbV4S8y8l6jfWTfnc+PZv4zVVlo/fGX1LuH4i8xh+HfVXVmJqQP7rqO9duUdZH9vEi6pvEPp32Ws1tvWwx9v02ZgqQj6Q+pdXN+ffB9wXwvmXHldJvreUO2HhewY3PFJTf9x8iGLU8tzFJl6h/LR4f1iAJ4QQT9O7fXgdUjqWE42A9mpynVFvwRjfKwDEvKVHVPi8xPjSgdWd8c7AAAA4DenY7geAAAAAMsClDwAAACwokDJAwAAACsKlDwAAACwokDJAwAAACsKlDwAAACwokDJAwAAACsKlDwAAACwokDJAwAAACsKlDwAAACwokDJAwAAACsKlDwAAACwkhD9P+QwuJ+dYUXBAAAAAElFTkSuQmCC)
<br>
Los resultados muestran que, en general, la cross validation  mejora ligeramente la precisión de los modelos comparado con el uso de un único conjunto de prueba. Para GaussianNB, la precisión aumenta de 0.7989 a 0.8081, mientras que para BernoulliNB, la mejora es de 0.7877 a 0.7935.
Aunque las diferencias son pequeñas, cross validation ofrece una estimación más robusta y generalizada del rendimiento. Esto sugiere que el uso de Cross Validation es preferible para evaluar modelos en tareas con alta variabilidad en los datos, como en este caso.

## Comparativa de precisión
"""

import matplotlib.pyplot as plt
import pandas as pd

# Datos simulados de resultados (puedes reemplazarlos con tus resultados reales)
results_no_cv = {'GaussianNB': 0.85, 'BernoulliNB': 0.78}
results_cv = {'GaussianNB': 0.88, 'BernoulliNB': 0.80}

# Crear un DataFrame para los resultados
comparison = pd.DataFrame({
    "Sin Cross Validation": results_no_cv,
    "Con Cross Validation": results_cv
})

# Gráfico de barras para comparar los resultados
fig, ax = plt.subplots(figsize=(8, 5))
comparison.plot(kind='bar', ax=ax, color=['skyblue', 'orange'], edgecolor='black')
ax.set_title('Comparación de Modelos Naive Bayes (Accuracy)', fontsize=14)
ax.set_ylabel('Accuracy', fontsize=12)
ax.set_xlabel('Modelos', fontsize=12)
ax.set_xticklabels(comparison.index, rotation=0, fontsize=11)
ax.legend(title='Evaluación', fontsize=10)
ax.grid(axis='y', linestyle='--', alpha=0.7)

# Mostrar el gráfico
plt.tight_layout()
plt.show()