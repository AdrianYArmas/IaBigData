{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab\n"
      ],
      "metadata": {
        "id": "uaXwBRKMdG84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab es una herramienta online gratuita basada en la nube que permite desplegar modelos de aprendizaje automático de forma remota en **CPUs y GPUs**\n",
        "\n",
        "Se basa en la tecnología de código abierto **Jupyter**, con la que se puede crear un cuaderno **Ipython**. El cuaderno Ipython no sólo te ofrece la posibilidad de escribir código, sino también de *contar una historia* a través de él.\n",
        "\n",
        "Puedes ejecutar código, crear visualizaciones dedatos, y escribir sobre cada paso que se haga en texto plano o markdown. Esto hace que el código incluya explicaciones y visualizaciones de lo que hace."
      ],
      "metadata": {
        "id": "xnxonCkcdVxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Que recursos ofrece Colab?\n"
      ],
      "metadata": {
        "id": "vT19_2audX6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Uso de Disco"
      ],
      "metadata": {
        "id": "dI94YgptdglK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnpJQcGOdA6l",
        "outputId": "1fc6766b-5c2b-4f84-d36d-bd7dde0fd360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         108G   42G   67G  39% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.8G     0  5.8G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  820M  59% /usr/sbin/docker-init\n",
            "tmpfs           6.4G   60K  6.4G   1% /var/colab\n",
            "/dev/sda1        77G   57G   20G  75% /etc/hosts\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ],
      "source": [
        "!df -h"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CPU's"
      ],
      "metadata": {
        "id": "0TdEAryWdiD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo | grep \"model name\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKG7LPFVdfCG",
        "outputId": "662d2995-b832-40c3-d57b-5d6450902b90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Memoria"
      ],
      "metadata": {
        "id": "v8JsiHaGdkv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo | grep \"Mem\"*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4ieBk40dkc3",
        "outputId": "699333e3-a2c3-432d-8ff1-3278ece0ff4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13290460 kB\n",
            "MemFree:         8124020 kB\n",
            "MemAvailable:   12209084 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* GPU\n",
        "\n",
        "Si activamos el soporte GPU entonces podremos obtener información sobre la misma\n",
        "Información sobre la GPU disponible\n",
        "\n",
        "`nvidia-smi -L` solo lista el nombre\n",
        "\n",
        "`nvidia-smi -q ` mucha más información disponible"
      ],
      "metadata": {
        "id": "RRhzD1mJdrlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_dzxrA6duc3",
        "outputId": "05a1960b-576d-4d16-f8bd-49cce88250b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "imTz6nmwdve-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c098b399-4060-4ac8-e1ad-7c1a72201c7f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/driver/nvidia/gpus/0000:00:04.0/information"
      ],
      "metadata": {
        "id": "8izVXeDedw7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hadoop"
      ],
      "metadata": {
        "id": "d3-j-3-td0sZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hadoop es un marco de programación basado en Java que permite procesar y almacenar conjuntos de datos extremadamente grandes en un clúster de máquinas de bajo coste. Fue el primer gran proyecto de código abierto en el ámbito del Big Data y está patrocinado por la Apache Software Foundation."
      ],
      "metadata": {
        "id": "HBwwvw6GeHys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalación de Hadoop"
      ],
      "metadata": {
        "id": "zvMUeqI8eKzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* bajar la distribución correspondiente"
      ],
      "metadata": {
        "id": "N45XMNJfeNBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz"
      ],
      "metadata": {
        "id": "FaSWVHUBeKJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6ab530b-d170-4fca-8b21-0a5a21218ba7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-07 17:33:46--  https://downloads.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.208.237, 2a01:4f9:3a:2c57::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 974002355 (929M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.4.1.tar.gz’\n",
            "\n",
            "hadoop-3.4.1.tar.gz 100%[===================>] 928.88M  27.3MB/s    in 34s     \n",
            "\n",
            "2024-11-07 17:34:20 (27.4 MB/s) - ‘hadoop-3.4.1.tar.gz’ saved [974002355/974002355]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* extraerla en el sistema de archivos de colab"
      ],
      "metadata": {
        "id": "RvoEmhuXeP58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf hadoop-3.4.1.tar.gz"
      ],
      "metadata": {
        "id": "TZuSfPveesx-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* mover la distribución de hadoop  /usr/local"
      ],
      "metadata": {
        "id": "K0pqGNYve2Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv  hadoop-3.4.1/ /usr/local/"
      ],
      "metadata": {
        "id": "DYpR8ywaeq7F"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuración"
      ],
      "metadata": {
        "id": "GTC-UUBGekB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* actualizamos variables de entorno (JAVA_HOME, PATH)"
      ],
      "metadata": {
        "id": "FN2a-M_GfFXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"PATH\"] + \":\" + \"/usr/local/hadoop-3.4.1/bin\""
      ],
      "metadata": {
        "id": "JGalbE25fEy_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* comprobamos instalación"
      ],
      "metadata": {
        "id": "AH5ZYJOWfMIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hadoop version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1Zqjd5DfOfP",
        "outputId": "e8dee531-4faf-404b-d799-1ba3f40090d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hadoop 3.4.1\n",
            "Source code repository https://github.com/apache/hadoop.git -r 4d7825309348956336b8f06a08322b78422849b1\n",
            "Compiled by mthakur on 2024-10-09T14:57Z\n",
            "Compiled on platform linux-x86_64\n",
            "Compiled with protoc 3.23.4\n",
            "From source with checksum 7292fe9dba5e2e44e3a9f763fce3e680\n",
            "This command was run using /usr/local/hadoop-3.4.1/share/hadoop/common/hadoop-common-3.4.1.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejecución de ejemplos"
      ],
      "metadata": {
        "id": "QghmXYaEfmXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una de las formas tradicionales de asegurarnos que un ambiente de Hadoop recién instalado funciona correctamente, es ejecutando el *jar* de ejemplos *map-reduce* incluido con toda instalación de hadoop (*hadoop-mapreduce-examples.jar*).\n",
        "\n",
        "[Hadoop Map Reduce Examples](http://svn.apache.org/viewvc/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/)"
      ],
      "metadata": {
        "id": "LDz8lgGGfwHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Creamos un directorio de ficheros en los que volquemos los xml de hadoop"
      ],
      "metadata": {
        "id": "qG7QK3i5fxqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mkdir ~/input\n",
        "cp /usr/local/hadoop-3.4.1/etc/hadoop/*.xml ~/input\n",
        "ls ~/input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XDprG74fowi",
        "outputId": "f683be86-11d3-40c0-c06e-48e64479e66e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "capacity-scheduler.xml\n",
            "core-site.xml\n",
            "hadoop-policy.xml\n",
            "hdfs-rbf-site.xml\n",
            "hdfs-site.xml\n",
            "httpfs-site.xml\n",
            "kms-acls.xml\n",
            "kms-site.xml\n",
            "mapred-site.xml\n",
            "yarn-site.xml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "mkdir: cannot create directory ‘/root/input’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ejecutamos hadoop jar con el fin de ejecutar uno de los ejemplos por defecto, en este caso el grep que busca expresiones regulares dentro de los ficheros que le especifiquemos."
      ],
      "metadata": {
        "id": "FNMVFo_Df4f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "hadoop jar \\\n",
        "  /usr/local/hadoop-3.4.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.4.1.jar \\\n",
        "  grep ~/input ~/grep_example 'allowed[.]*'"
      ],
      "metadata": {
        "id": "iffiuEsZgJf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cbecc81-30aa-4ba8-de5e-ab9f2d882ea4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-07 17:40:47,449 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2024-11-07 17:40:47,763 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2024-11-07 17:40:47,764 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2024-11-07 17:40:48,283 INFO input.FileInputFormat: Total input files to process : 10\n",
            "2024-11-07 17:40:48,352 INFO mapreduce.JobSubmitter: number of splits:10\n",
            "2024-11-07 17:40:48,902 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1475880293_0001\n",
            "2024-11-07 17:40:48,903 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2024-11-07 17:40:49,191 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2024-11-07 17:40:49,192 INFO mapreduce.Job: Running job: job_local1475880293_0001\n",
            "2024-11-07 17:40:49,201 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2024-11-07 17:40:49,214 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:49,216 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:49,216 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:49,221 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
            "2024-11-07 17:40:49,296 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2024-11-07 17:40:49,298 INFO mapred.LocalJobRunner: Starting task: attempt_local1475880293_0001_m_000000_0\n",
            "2024-11-07 17:40:49,332 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:49,334 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:49,334 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:49,368 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:49,374 INFO mapred.MapTask: Processing split: file:/root/input/hadoop-policy.xml:0+14007\n",
            "2024-11-07 17:40:49,472 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-11-07 17:40:49,472 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-11-07 17:40:49,472 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-11-07 17:40:49,472 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-11-07 17:40:49,472 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-11-07 17:40:49,478 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-11-07 17:40:49,511 INFO mapred.LocalJobRunner: \n",
            "2024-11-07 17:40:49,512 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-11-07 17:40:49,512 INFO mapred.MapTask: Spilling map output\n",
            "2024-11-07 17:40:49,512 INFO mapred.MapTask: bufstart = 0; bufend = 459; bufvoid = 104857600\n",
            "2024-11-07 17:40:49,512 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214292(104857168); length = 105/6553600\n",
            "2024-11-07 17:40:49,530 INFO mapred.MapTask: Finished spill 0\n",
            "2024-11-07 17:40:49,547 INFO mapred.Task: Task:attempt_local1475880293_0001_m_000000_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:49,552 INFO mapred.LocalJobRunner: map\n",
            "2024-11-07 17:40:49,553 INFO mapred.Task: Task 'attempt_local1475880293_0001_m_000000_0' done.\n",
            "2024-11-07 17:40:49,562 INFO mapred.Task: Final Counters for attempt_local1475880293_0001_m_000000_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=296800\n",
            "\t\tFILE: Number of bytes written=998259\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=325\n",
            "\t\tMap output records=27\n",
            "\t\tMap output bytes=459\n",
            "\t\tMap output materialized bytes=25\n",
            "\t\tInput split bytes=99\n",
            "\t\tCombine input records=27\n",
            "\t\tCombine output records=1\n",
            "\t\tSpilled Records=1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=397410304\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=14007\n",
            "2024-11-07 17:40:49,562 INFO mapred.LocalJobRunner: Finishing task: attempt_local1475880293_0001_m_000000_0\n",
            "2024-11-07 17:40:49,564 INFO mapred.LocalJobRunner: Starting task: attempt_local1475880293_0001_m_000001_0\n",
            "2024-11-07 17:40:49,567 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:49,567 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:49,568 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:49,568 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:49,574 INFO mapred.MapTask: Processing split: file:/root/input/capacity-scheduler.xml:0+9213\n",
            "2024-11-07 17:40:49,623 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-11-07 17:40:49,623 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-11-07 17:40:49,623 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-11-07 17:40:49,623 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-11-07 17:40:49,623 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-11-07 17:40:49,646 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-11-07 17:40:49,667 INFO mapred.LocalJobRunner: \n",
            "2024-11-07 17:40:49,673 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-11-07 17:40:49,673 INFO mapred.MapTask: Spilling map output\n",
            "2024-11-07 17:40:49,673 INFO mapred.MapTask: bufstart = 0; bufend = 16; bufvoid = 104857600\n",
            "2024-11-07 17:40:49,673 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
            "2024-11-07 17:40:49,676 INFO mapred.MapTask: Finished spill 0\n",
            "2024-11-07 17:40:49,688 INFO mapred.Task: Task:attempt_local1475880293_0001_m_000001_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:49,691 INFO mapred.LocalJobRunner: map\n",
            "2024-11-07 17:40:49,691 INFO mapred.Task: Task 'attempt_local1475880293_0001_m_000001_0' done.\n",
            "2024-11-07 17:40:49,692 INFO mapred.Task: Final Counters for attempt_local1475880293_0001_m_000001_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=307005\n",
            "\t\tFILE: Number of bytes written=998315\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=244\n",
            "\t\tMap output records=1\n",
            "\t\tMap output bytes=16\n",
            "\t\tMap output materialized bytes=24\n",
            "\t\tInput split bytes=104\n",
            "\t\tCombine input records=1\n",
            "\t\tCombine output records=1\n",
            "\t\tSpilled Records=1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=19\n",
            "\t\tTotal committed heap usage (bytes)=397410304\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=9213\n",
            "2024-11-07 17:40:49,692 INFO mapred.LocalJobRunner: Finishing task: attempt_local1475880293_0001_m_000001_0\n",
            "2024-11-07 17:40:49,692 INFO mapred.LocalJobRunner: Starting task: attempt_local1475880293_0001_m_000002_0\n",
            "2024-11-07 17:40:49,695 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:49,695 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:49,697 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:49,698 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:49,703 INFO mapred.MapTask: Processing split: file:/root/input/kms-acls.xml:0+3518\n",
            "2024-11-07 17:40:49,748 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-11-07 17:40:49,751 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-11-07 17:40:49,751 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-11-07 17:40:49,751 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-11-07 17:40:49,751 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-11-07 17:40:49,752 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-11-07 17:40:49,778 INFO mapred.LocalJobRunner: \n",
            "2024-11-07 17:40:49,780 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-11-07 17:40:49,787 INFO mapred.Task: Task:attempt_local1475880293_0001_m_000002_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:49,793 INFO mapred.LocalJobRunner: map\n",
            "2024-11-07 17:40:49,794 INFO mapred.Task: Task 'attempt_local1475880293_0001_m_000002_0' done.\n",
            "2024-11-07 17:40:49,794 INFO mapred.Task: Final Counters for attempt_local1475880293_0001_m_000002_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=311515\n",
            "\t\tFILE: Number of bytes written=998353\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=135\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=94\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=12\n",
            "\t\tTotal committed heap usage (bytes)=397410304\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=3518\n",
            "2024-11-07 17:40:49,794 INFO mapred.LocalJobRunner: Finishing task: attempt_local1475880293_0001_m_000002_0\n",
            "2024-11-07 17:40:49,795 INFO mapred.LocalJobRunner: Starting task: attempt_local1475880293_0001_m_000003_0\n",
            "2024-11-07 17:40:49,799 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:49,799 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:49,799 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:49,800 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:49,809 INFO mapred.MapTask: Processing split: file:/root/input/hdfs-site.xml:0+775\n",
            "2024-11-07 17:40:49,841 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-11-07 17:40:49,841 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-11-07 17:40:49,841 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-11-07 17:40:49,841 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-11-07 17:40:49,841 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-11-07 17:40:49,842 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-11-07 17:40:49,847 INFO mapred.LocalJobRunner: \n",
            "2024-11-07 17:40:49,848 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-11-07 17:40:49,853 INFO mapred.Task: Task:attempt_local1475880293_0001_m_000003_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:49,857 INFO mapred.LocalJobRunner: map\n",
            "2024-11-07 17:40:49,857 INFO mapred.Task: Task 'attempt_local1475880293_0001_m_000003_0' done.\n",
            "2024-11-07 17:40:49,864 INFO mapred.Task: Final Counters for attempt_local1475880293_0001_m_000003_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=313282\n",
            "\t\tFILE: Number of bytes written=998391\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=21\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=95\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=11\n",
            "\t\tTotal committed heap usage (bytes)=495976448\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=775\n",
            "2024-11-07 17:40:49,864 INFO mapred.LocalJobRunner: Finishing task: attempt_local1475880293_0001_m_000003_0\n",
            "2024-11-07 17:40:49,864 INFO mapred.LocalJobRunner: Starting task: attempt_local1475880293_0001_m_000004_0\n",
            "2024-11-07 17:40:49,876 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:49,876 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:49,876 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:49,876 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:49,885 INFO mapred.MapTask: Processing split: file:/root/input/core-site.xml:0+774\n",
            "2024-11-07 17:40:49,958 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-11-07 17:40:49,958 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-11-07 17:40:49,959 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-11-07 17:40:49,959 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-11-07 17:40:49,959 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-11-07 17:40:49,962 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-11-07 17:40:49,968 INFO mapred.LocalJobRunner: \n",
            "2024-11-07 17:40:49,971 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-11-07 17:40:49,976 INFO mapred.Task: Task:attempt_local1475880293_0001_m_000004_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:49,981 INFO mapred.LocalJobRunner: map\n",
            "2024-11-07 17:40:49,982 INFO mapred.Task: Task 'attempt_local1475880293_0001_m_000004_0' done.\n",
            "2024-11-07 17:40:49,982 INFO mapred.Task: Final Counters for attempt_local1475880293_0001_m_000004_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=315048\n",
            "\t\tFILE: Number of bytes written=998429\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=20\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=95\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=495976448\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=774\n",
            "2024-11-07 17:40:49,984 INFO mapred.LocalJobRunner: Finishing task: attempt_local1475880293_0001_m_000004_0\n",
            "2024-11-07 17:40:49,984 INFO mapred.LocalJobRunner: Starting task: attempt_local1475880293_0001_m_000005_0\n",
            "2024-11-07 17:40:49,985 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:49,985 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:49,985 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:49,986 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:49,988 INFO mapred.MapTask: Processing split: file:/root/input/mapred-site.xml:0+758\n",
            "2024-11-07 17:40:50,017 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-11-07 17:40:50,017 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-11-07 17:40:50,017 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-11-07 17:40:50,017 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-11-07 17:40:50,018 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-11-07 17:40:50,019 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-11-07 17:40:50,037 INFO mapred.LocalJobRunner: \n",
            "2024-11-07 17:40:50,039 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-11-07 17:40:50,045 INFO mapred.Task: Task:attempt_local1475880293_0001_m_000005_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:50,047 INFO mapred.LocalJobRunner: map\n",
            "2024-11-07 17:40:50,047 INFO mapred.Task: Task 'attempt_local1475880293_0001_m_000005_0' done.\n",
            "2024-11-07 17:40:50,051 INFO mapred.Task: Final Counters for attempt_local1475880293_0001_m_000005_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=316798\n",
            "\t\tFILE: Number of bytes written=998467\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=21\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=97\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=8\n",
            "\t\tTotal committed heap usage (bytes)=495976448\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=758\n",
            "2024-11-07 17:40:50,052 INFO mapred.LocalJobRunner: Finishing task: attempt_local1475880293_0001_m_000005_0\n",
            "2024-11-07 17:40:50,052 INFO mapred.LocalJobRunner: Starting task: attempt_local1475880293_0001_m_000006_0\n",
            "2024-11-07 17:40:50,053 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:50,053 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:50,053 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:50,054 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:50,059 INFO mapred.MapTask: Processing split: file:/root/input/yarn-site.xml:0+690\n",
            "2024-11-07 17:40:50,101 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-11-07 17:40:50,101 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-11-07 17:40:50,101 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-11-07 17:40:50,101 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-11-07 17:40:50,101 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-11-07 17:40:50,104 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-11-07 17:40:50,111 INFO mapred.LocalJobRunner: \n",
            "2024-11-07 17:40:50,113 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-11-07 17:40:50,120 INFO mapred.Task: Task:attempt_local1475880293_0001_m_000006_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:50,125 INFO mapred.LocalJobRunner: map\n",
            "2024-11-07 17:40:50,125 INFO mapred.Task: Task 'attempt_local1475880293_0001_m_000006_0' done.\n",
            "2024-11-07 17:40:50,125 INFO mapred.Task: Final Counters for attempt_local1475880293_0001_m_000006_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=317968\n",
            "\t\tFILE: Number of bytes written=998505\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=19\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=95\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=9\n",
            "\t\tTotal committed heap usage (bytes)=495976448\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=690\n",
            "2024-11-07 17:40:50,126 INFO mapred.LocalJobRunner: Finishing task: attempt_local1475880293_0001_m_000006_0\n",
            "2024-11-07 17:40:50,126 INFO mapred.LocalJobRunner: Starting task: attempt_local1475880293_0001_m_000007_0\n",
            "2024-11-07 17:40:50,128 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:50,128 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:50,128 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:50,128 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:50,130 INFO mapred.MapTask: Processing split: file:/root/input/hdfs-rbf-site.xml:0+683\n",
            "2024-11-07 17:40:50,158 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-11-07 17:40:50,158 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-11-07 17:40:50,158 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-11-07 17:40:50,158 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-11-07 17:40:50,158 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-11-07 17:40:50,159 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-11-07 17:40:50,171 INFO mapred.LocalJobRunner: \n",
            "2024-11-07 17:40:50,172 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-11-07 17:40:50,180 INFO mapred.Task: Task:attempt_local1475880293_0001_m_000007_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:50,182 INFO mapred.LocalJobRunner: map\n",
            "2024-11-07 17:40:50,182 INFO mapred.Task: Task 'attempt_local1475880293_0001_m_000007_0' done.\n",
            "2024-11-07 17:40:50,184 INFO mapred.Task: Final Counters for attempt_local1475880293_0001_m_000007_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=319131\n",
            "\t\tFILE: Number of bytes written=998543\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=20\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=99\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=5\n",
            "\t\tTotal committed heap usage (bytes)=495976448\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=683\n",
            "2024-11-07 17:40:50,184 INFO mapred.LocalJobRunner: Finishing task: attempt_local1475880293_0001_m_000007_0\n",
            "2024-11-07 17:40:50,185 INFO mapred.LocalJobRunner: Starting task: attempt_local1475880293_0001_m_000008_0\n",
            "2024-11-07 17:40:50,189 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:50,190 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:50,190 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:50,191 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:50,193 INFO mapred.MapTask: Processing split: file:/root/input/kms-site.xml:0+682\n",
            "2024-11-07 17:40:50,207 INFO mapreduce.Job: Job job_local1475880293_0001 running in uber mode : false\n",
            "2024-11-07 17:40:50,216 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-11-07 17:40:50,217 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-11-07 17:40:50,217 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-11-07 17:40:50,217 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-11-07 17:40:50,217 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-11-07 17:40:50,220 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2024-11-07 17:40:50,221 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-11-07 17:40:50,227 INFO mapred.LocalJobRunner: \n",
            "2024-11-07 17:40:50,227 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-11-07 17:40:50,233 INFO mapred.Task: Task:attempt_local1475880293_0001_m_000008_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:50,235 INFO mapred.LocalJobRunner: map\n",
            "2024-11-07 17:40:50,235 INFO mapred.Task: Task 'attempt_local1475880293_0001_m_000008_0' done.\n",
            "2024-11-07 17:40:50,235 INFO mapred.Task: Final Counters for attempt_local1475880293_0001_m_000008_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=320293\n",
            "\t\tFILE: Number of bytes written=998581\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=20\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=94\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=5\n",
            "\t\tTotal committed heap usage (bytes)=495976448\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=682\n",
            "2024-11-07 17:40:50,235 INFO mapred.LocalJobRunner: Finishing task: attempt_local1475880293_0001_m_000008_0\n",
            "2024-11-07 17:40:50,235 INFO mapred.LocalJobRunner: Starting task: attempt_local1475880293_0001_m_000009_0\n",
            "2024-11-07 17:40:50,237 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:50,237 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:50,237 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:50,237 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:50,239 INFO mapred.MapTask: Processing split: file:/root/input/httpfs-site.xml:0+620\n",
            "2024-11-07 17:40:50,256 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-11-07 17:40:50,256 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-11-07 17:40:50,256 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-11-07 17:40:50,256 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-11-07 17:40:50,256 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-11-07 17:40:50,257 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-11-07 17:40:50,267 INFO mapred.LocalJobRunner: \n",
            "2024-11-07 17:40:50,268 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-11-07 17:40:50,274 INFO mapred.Task: Task:attempt_local1475880293_0001_m_000009_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:50,276 INFO mapred.LocalJobRunner: map\n",
            "2024-11-07 17:40:50,276 INFO mapred.Task: Task 'attempt_local1475880293_0001_m_000009_0' done.\n",
            "2024-11-07 17:40:50,276 INFO mapred.Task: Final Counters for attempt_local1475880293_0001_m_000009_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=321393\n",
            "\t\tFILE: Number of bytes written=998619\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=17\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=97\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=495976448\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=620\n",
            "2024-11-07 17:40:50,276 INFO mapred.LocalJobRunner: Finishing task: attempt_local1475880293_0001_m_000009_0\n",
            "2024-11-07 17:40:50,276 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2024-11-07 17:40:50,284 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2024-11-07 17:40:50,285 INFO mapred.LocalJobRunner: Starting task: attempt_local1475880293_0001_r_000000_0\n",
            "2024-11-07 17:40:50,295 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:50,295 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:50,295 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:50,295 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:50,299 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19d14f03\n",
            "2024-11-07 17:40:50,301 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2024-11-07 17:40:50,335 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2024-11-07 17:40:50,338 INFO reduce.EventFetcher: attempt_local1475880293_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2024-11-07 17:40:50,385 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1475880293_0001_m_000009_0 decomp: 2 len: 6 to MEMORY\n",
            "2024-11-07 17:40:50,389 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1475880293_0001_m_000009_0\n",
            "2024-11-07 17:40:50,395 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2\n",
            "2024-11-07 17:40:50,400 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1475880293_0001_m_000003_0 decomp: 2 len: 6 to MEMORY\n",
            "2024-11-07 17:40:50,402 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1475880293_0001_m_000003_0\n",
            "2024-11-07 17:40:50,402 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4\n",
            "2024-11-07 17:40:50,405 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1475880293_0001_m_000006_0 decomp: 2 len: 6 to MEMORY\n",
            "2024-11-07 17:40:50,408 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1475880293_0001_m_000006_0\n",
            "2024-11-07 17:40:50,409 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6\n",
            "2024-11-07 17:40:50,411 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1475880293_0001_m_000005_0 decomp: 2 len: 6 to MEMORY\n",
            "2024-11-07 17:40:50,412 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1475880293_0001_m_000005_0\n",
            "2024-11-07 17:40:50,412 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8\n",
            "2024-11-07 17:40:50,414 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1475880293_0001_m_000008_0 decomp: 2 len: 6 to MEMORY\n",
            "2024-11-07 17:40:50,414 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1475880293_0001_m_000008_0\n",
            "2024-11-07 17:40:50,415 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->10\n",
            "2024-11-07 17:40:50,417 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1475880293_0001_m_000002_0 decomp: 2 len: 6 to MEMORY\n",
            "2024-11-07 17:40:50,417 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1475880293_0001_m_000002_0\n",
            "2024-11-07 17:40:50,418 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 10, usedMemory ->12\n",
            "2024-11-07 17:40:50,419 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1475880293_0001_m_000001_0 decomp: 20 len: 24 to MEMORY\n",
            "2024-11-07 17:40:50,420 INFO reduce.InMemoryMapOutput: Read 20 bytes from map-output for attempt_local1475880293_0001_m_000001_0\n",
            "2024-11-07 17:40:50,420 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 7, commitMemory -> 12, usedMemory ->32\n",
            "2024-11-07 17:40:50,422 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1475880293_0001_m_000004_0 decomp: 2 len: 6 to MEMORY\n",
            "2024-11-07 17:40:50,423 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1475880293_0001_m_000004_0\n",
            "2024-11-07 17:40:50,423 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 8, commitMemory -> 32, usedMemory ->34\n",
            "2024-11-07 17:40:50,425 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1475880293_0001_m_000000_0 decomp: 21 len: 25 to MEMORY\n",
            "2024-11-07 17:40:50,425 INFO reduce.InMemoryMapOutput: Read 21 bytes from map-output for attempt_local1475880293_0001_m_000000_0\n",
            "2024-11-07 17:40:50,426 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 21, inMemoryMapOutputs.size() -> 9, commitMemory -> 34, usedMemory ->55\n",
            "2024-11-07 17:40:50,428 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1475880293_0001_m_000007_0 decomp: 2 len: 6 to MEMORY\n",
            "2024-11-07 17:40:50,428 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1475880293_0001_m_000007_0\n",
            "2024-11-07 17:40:50,428 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 10, commitMemory -> 55, usedMemory ->57\n",
            "2024-11-07 17:40:50,429 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2024-11-07 17:40:50,430 INFO mapred.LocalJobRunner: 10 / 10 copied.\n",
            "2024-11-07 17:40:50,430 INFO reduce.MergeManagerImpl: finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2024-11-07 17:40:50,437 INFO mapred.Merger: Merging 10 sorted segments\n",
            "2024-11-07 17:40:50,438 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 20 bytes\n",
            "2024-11-07 17:40:50,439 INFO reduce.MergeManagerImpl: Merged 10 segments, 57 bytes to disk to satisfy reduce memory limit\n",
            "2024-11-07 17:40:50,440 INFO reduce.MergeManagerImpl: Merging 1 files, 43 bytes from disk\n",
            "2024-11-07 17:40:50,440 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2024-11-07 17:40:50,440 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2024-11-07 17:40:50,441 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n",
            "2024-11-07 17:40:50,442 INFO mapred.LocalJobRunner: 10 / 10 copied.\n",
            "2024-11-07 17:40:50,470 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2024-11-07 17:40:50,472 INFO mapred.Task: Task:attempt_local1475880293_0001_r_000000_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:50,475 INFO mapred.LocalJobRunner: 10 / 10 copied.\n",
            "2024-11-07 17:40:50,476 INFO mapred.Task: Task attempt_local1475880293_0001_r_000000_0 is allowed to commit now\n",
            "2024-11-07 17:40:50,478 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1475880293_0001_r_000000_0' to file:/content/grep-temp-1724072603\n",
            "2024-11-07 17:40:50,479 INFO mapred.LocalJobRunner: reduce > reduce\n",
            "2024-11-07 17:40:50,479 INFO mapred.Task: Task 'attempt_local1475880293_0001_r_000000_0' done.\n",
            "2024-11-07 17:40:50,485 INFO mapred.Task: Final Counters for attempt_local1475880293_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=321853\n",
            "\t\tFILE: Number of bytes written=998809\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=97\n",
            "\t\tReduce input records=2\n",
            "\t\tReduce output records=2\n",
            "\t\tSpilled Records=2\n",
            "\t\tShuffled Maps =10\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=10\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=495976448\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=147\n",
            "2024-11-07 17:40:50,487 INFO mapred.LocalJobRunner: Finishing task: attempt_local1475880293_0001_r_000000_0\n",
            "2024-11-07 17:40:50,490 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2024-11-07 17:40:51,226 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2024-11-07 17:40:51,227 INFO mapreduce.Job: Job job_local1475880293_0001 completed successfully\n",
            "2024-11-07 17:40:51,252 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=3461086\n",
            "\t\tFILE: Number of bytes written=10983271\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=842\n",
            "\t\tMap output records=28\n",
            "\t\tMap output bytes=475\n",
            "\t\tMap output materialized bytes=97\n",
            "\t\tInput split bytes=969\n",
            "\t\tCombine input records=28\n",
            "\t\tCombine output records=2\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=97\n",
            "\t\tReduce input records=2\n",
            "\t\tReduce output records=2\n",
            "\t\tSpilled Records=4\n",
            "\t\tShuffled Maps =10\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=10\n",
            "\t\tGC time elapsed (ms)=69\n",
            "\t\tTotal committed heap usage (bytes)=5160042496\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=31720\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=147\n",
            "2024-11-07 17:40:51,282 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2024-11-07 17:40:51,302 INFO input.FileInputFormat: Total input files to process : 1\n",
            "2024-11-07 17:40:51,305 INFO mapreduce.JobSubmitter: number of splits:1\n",
            "2024-11-07 17:40:51,351 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1184279848_0002\n",
            "2024-11-07 17:40:51,351 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2024-11-07 17:40:51,516 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2024-11-07 17:40:51,516 INFO mapreduce.Job: Running job: job_local1184279848_0002\n",
            "2024-11-07 17:40:51,517 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2024-11-07 17:40:51,517 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:51,517 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:51,517 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:51,518 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
            "2024-11-07 17:40:51,525 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2024-11-07 17:40:51,526 INFO mapred.LocalJobRunner: Starting task: attempt_local1184279848_0002_m_000000_0\n",
            "2024-11-07 17:40:51,528 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:51,528 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:51,528 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:51,528 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:51,535 INFO mapred.MapTask: Processing split: file:/content/grep-temp-1724072603/part-r-00000:0+135\n",
            "2024-11-07 17:40:51,585 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-11-07 17:40:51,585 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-11-07 17:40:51,586 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-11-07 17:40:51,586 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-11-07 17:40:51,586 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-11-07 17:40:51,593 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-11-07 17:40:51,619 INFO mapred.LocalJobRunner: \n",
            "2024-11-07 17:40:51,621 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-11-07 17:40:51,621 INFO mapred.MapTask: Spilling map output\n",
            "2024-11-07 17:40:51,622 INFO mapred.MapTask: bufstart = 0; bufend = 33; bufvoid = 104857600\n",
            "2024-11-07 17:40:51,622 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2024-11-07 17:40:51,625 INFO mapred.MapTask: Finished spill 0\n",
            "2024-11-07 17:40:51,629 INFO mapred.Task: Task:attempt_local1184279848_0002_m_000000_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:51,630 INFO mapred.LocalJobRunner: map\n",
            "2024-11-07 17:40:51,630 INFO mapred.Task: Task 'attempt_local1184279848_0002_m_000000_0' done.\n",
            "2024-11-07 17:40:51,631 INFO mapred.Task: Final Counters for attempt_local1184279848_0002_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=603781\n",
            "\t\tFILE: Number of bytes written=1994773\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=2\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=33\n",
            "\t\tMap output materialized bytes=43\n",
            "\t\tInput split bytes=112\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=12\n",
            "\t\tTotal committed heap usage (bytes)=495976448\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=147\n",
            "2024-11-07 17:40:51,631 INFO mapred.LocalJobRunner: Finishing task: attempt_local1184279848_0002_m_000000_0\n",
            "2024-11-07 17:40:51,631 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2024-11-07 17:40:51,632 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2024-11-07 17:40:51,633 INFO mapred.LocalJobRunner: Starting task: attempt_local1184279848_0002_r_000000_0\n",
            "2024-11-07 17:40:51,639 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
            "2024-11-07 17:40:51,640 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-11-07 17:40:51,640 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-11-07 17:40:51,640 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-11-07 17:40:51,640 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f51b905\n",
            "2024-11-07 17:40:51,641 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2024-11-07 17:40:51,643 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2024-11-07 17:40:51,646 INFO reduce.EventFetcher: attempt_local1184279848_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2024-11-07 17:40:51,652 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1184279848_0002_m_000000_0 decomp: 39 len: 43 to MEMORY\n",
            "2024-11-07 17:40:51,653 INFO reduce.InMemoryMapOutput: Read 39 bytes from map-output for attempt_local1184279848_0002_m_000000_0\n",
            "2024-11-07 17:40:51,654 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 39, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->39\n",
            "2024-11-07 17:40:51,655 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2024-11-07 17:40:51,655 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2024-11-07 17:40:51,656 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2024-11-07 17:40:51,657 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2024-11-07 17:40:51,657 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n",
            "2024-11-07 17:40:51,658 INFO reduce.MergeManagerImpl: Merged 1 segments, 39 bytes to disk to satisfy reduce memory limit\n",
            "2024-11-07 17:40:51,658 INFO reduce.MergeManagerImpl: Merging 1 files, 43 bytes from disk\n",
            "2024-11-07 17:40:51,658 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2024-11-07 17:40:51,658 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2024-11-07 17:40:51,659 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n",
            "2024-11-07 17:40:51,659 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2024-11-07 17:40:51,664 INFO mapred.Task: Task:attempt_local1184279848_0002_r_000000_0 is done. And is in the process of committing\n",
            "2024-11-07 17:40:51,664 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2024-11-07 17:40:51,665 INFO mapred.Task: Task attempt_local1184279848_0002_r_000000_0 is allowed to commit now\n",
            "2024-11-07 17:40:51,667 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1184279848_0002_r_000000_0' to file:/root/grep_example\n",
            "2024-11-07 17:40:51,668 INFO mapred.LocalJobRunner: reduce > reduce\n",
            "2024-11-07 17:40:51,668 INFO mapred.Task: Task 'attempt_local1184279848_0002_r_000000_0' done.\n",
            "2024-11-07 17:40:51,668 INFO mapred.Task: Final Counters for attempt_local1184279848_0002_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=603899\n",
            "\t\tFILE: Number of bytes written=1994850\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=43\n",
            "\t\tReduce input records=2\n",
            "\t\tReduce output records=2\n",
            "\t\tSpilled Records=2\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=495976448\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=34\n",
            "2024-11-07 17:40:51,668 INFO mapred.LocalJobRunner: Finishing task: attempt_local1184279848_0002_r_000000_0\n",
            "2024-11-07 17:40:51,668 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2024-11-07 17:40:52,517 INFO mapreduce.Job: Job job_local1184279848_0002 running in uber mode : false\n",
            "2024-11-07 17:40:52,517 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2024-11-07 17:40:52,517 INFO mapreduce.Job: Job job_local1184279848_0002 completed successfully\n",
            "2024-11-07 17:40:52,521 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1207680\n",
            "\t\tFILE: Number of bytes written=3989623\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=2\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=33\n",
            "\t\tMap output materialized bytes=43\n",
            "\t\tInput split bytes=112\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=43\n",
            "\t\tReduce input records=2\n",
            "\t\tReduce output records=2\n",
            "\t\tSpilled Records=4\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=12\n",
            "\t\tTotal committed heap usage (bytes)=991952896\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=147\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ~/grep_example/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkteR8esgZTs",
        "outputId": "f2b59223-e02c-4872-c68e-39e09d2102eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\tallowed.\n",
            "1\tallowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HDFS\n"
      ],
      "metadata": {
        "id": "2aHq4zezd-09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las siguientes sentencias únicamente sirven para probar comandos básicos de HDFS no para gestionar una Infraestructura que en Google Colab no existe, en este caso el sistema de archivos HDFS es el mismo que el local"
      ],
      "metadata": {
        "id": "KCkyAP77gkGi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPB6hnMc_Xeh"
      },
      "source": [
        "* Crear el directorio *prueba*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAGdEAYy_UDB"
      },
      "source": [
        "!hdfs dfs -mkdir prueba"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt4ovs9-vC47"
      },
      "source": [
        "- Crear un fichero local :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOCZWC2JvUOH",
        "outputId": "9693c4dc-c7f4-42d6-b83c-cee0149f4f07"
      },
      "source": [
        "%%bash\n",
        "echo \"Ejemplo de HDFS\" > user.txt\n",
        "echo `date` >> user.txt\n",
        "cat user.txt"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de HDFS\n",
            "Thu Nov 7 05:41:24 PM UTC 2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk4NIb_gvdNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6ab698-5fbb-4892-ac11-71df5a629ae7"
      },
      "source": [
        "!hdfs dfs -put user.txt prueba/\n",
        "!hdfs dfs -ls prueba"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 items\n",
            "-rw-r--r--   1 root root         47 2024-11-07 17:41 prueba/user.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXxnK8JA_0_9"
      },
      "source": [
        "- Mostrar su contenido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3C_cq5OvxNV",
        "outputId": "86c52438-8a6e-44c5-d012-f7847712ffc9"
      },
      "source": [
        "!hdfs dfs -cat prueba/user.txt"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de HDFS\n",
            "Thu Nov 7 05:41:24 PM UTC 2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRKP6oHOHcNL",
        "outputId": "9bb040ce-7608-44e8-b97c-e190a3b6b3f1"
      },
      "source": [
        "%%bash\n",
        "hdfs dfs -tail prueba/user.txt"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de HDFS\n",
            "Thu Nov 7 05:41:24 PM UTC 2024\n"
          ]
        }
      ]
    }
  ]
}