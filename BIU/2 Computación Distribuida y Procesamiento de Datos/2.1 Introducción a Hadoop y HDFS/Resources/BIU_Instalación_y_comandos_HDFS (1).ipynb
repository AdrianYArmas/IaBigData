{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab\n"
      ],
      "metadata": {
        "id": "uaXwBRKMdG84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab es una herramienta online gratuita basada en la nube que permite desplegar modelos de aprendizaje automático de forma remota en **CPUs y GPUs**\n",
        "\n",
        "Se basa en la tecnología de código abierto **Jupyter**, con la que se puede crear un cuaderno **Ipython**. El cuaderno Ipython no sólo te ofrece la posibilidad de escribir código, sino también de *contar una historia* a través de él.\n",
        "\n",
        "Puedes ejecutar código, crear visualizaciones dedatos, y escribir sobre cada paso que se haga en texto plano o markdown. Esto hace que el código incluya explicaciones y visualizaciones de lo que hace."
      ],
      "metadata": {
        "id": "xnxonCkcdVxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hadoop"
      ],
      "metadata": {
        "id": "d3-j-3-td0sZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hadoop es un marco de programación basado en Java que permite procesar y almacenar conjuntos de datos extremadamente grandes en un clúster de máquinas de bajo coste. Fue el primer gran proyecto de código abierto en el ámbito del Big Data y está patrocinado por la Apache Software Foundation."
      ],
      "metadata": {
        "id": "HBwwvw6GeHys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalación de Hadoop"
      ],
      "metadata": {
        "id": "zvMUeqI8eKzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* bajar la distribución correspondiente"
      ],
      "metadata": {
        "id": "N45XMNJfeNBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz"
      ],
      "metadata": {
        "id": "FaSWVHUBeKJp",
        "outputId": "7e4a6277-d043-4591-a3c8-b2781ead6eef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-24 20:21:40--  https://downloads.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 88.99.95.219, 135.181.214.104, 2a01:4f9:3a:2c57::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|88.99.95.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 638660563 (609M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.2.tar.gz’\n",
            "\n",
            "hadoop-3.3.2.tar.gz 100%[===================>] 609.07M  28.0MB/s    in 22s     \n",
            "\n",
            "2023-11-24 20:22:03 (27.4 MB/s) - ‘hadoop-3.3.2.tar.gz’ saved [638660563/638660563]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* extraerla en el sistema de archivos de colab"
      ],
      "metadata": {
        "id": "RvoEmhuXeP58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf hadoop-3.3.2.tar.gz"
      ],
      "metadata": {
        "id": "TZuSfPveesx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* mover la distribución de hadoop  /usr/local"
      ],
      "metadata": {
        "id": "K0pqGNYve2Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv  hadoop-3.3.2/ /usr/local/"
      ],
      "metadata": {
        "id": "DYpR8ywaeq7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuración"
      ],
      "metadata": {
        "id": "GTC-UUBGekB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* actualizamos variables de entorno (JAVA_HOME, PATH)"
      ],
      "metadata": {
        "id": "FN2a-M_GfFXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"PATH\"] + \":\" + \"/usr/local/hadoop-3.3.2/bin\""
      ],
      "metadata": {
        "id": "JGalbE25fEy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* comprobamos instalación"
      ],
      "metadata": {
        "id": "AH5ZYJOWfMIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hadoop version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1Zqjd5DfOfP",
        "outputId": "998f9fbb-49b1-425b-a7a3-bb87ee4a560b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hadoop 3.3.2\n",
            "Source code repository git@github.com:apache/hadoop.git -r 0bcb014209e219273cb6fd4152df7df713cbac61\n",
            "Compiled by chao on 2022-02-21T18:39Z\n",
            "Compiled with protoc 3.7.1\n",
            "From source with checksum 4b40fff8bb27201ba07b6fa5651217fb\n",
            "This command was run using /usr/local/hadoop-3.3.2/share/hadoop/common/hadoop-common-3.3.2.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejecución de ejemplos"
      ],
      "metadata": {
        "id": "QghmXYaEfmXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una de las formas tradicionales de asegurarnos que un ambiente de Hadoop recién instalado funciona correctamente, es ejecutando el *jar* de ejemplos *map-reduce* incluido con toda instalación de hadoop (*hadoop-mapreduce-examples.jar*).\n",
        "\n",
        "[Hadoop Map Reduce Examples](http://svn.apache.org/viewvc/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/)"
      ],
      "metadata": {
        "id": "LDz8lgGGfwHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Creamos un directorio de ficheros en los que volquemos los xml de hadoop"
      ],
      "metadata": {
        "id": "qG7QK3i5fxqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mkdir ~/input\n",
        "cp /usr/local/hadoop-3.3.2/etc/hadoop/*.xml ~/input\n",
        "ls ~/input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XDprG74fowi",
        "outputId": "c681a745-3865-46cf-c3c4-e4a0b3163b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "capacity-scheduler.xml\n",
            "core-site.xml\n",
            "hadoop-policy.xml\n",
            "hdfs-rbf-site.xml\n",
            "hdfs-site.xml\n",
            "httpfs-site.xml\n",
            "kms-acls.xml\n",
            "kms-site.xml\n",
            "mapred-site.xml\n",
            "yarn-site.xml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "mkdir: cannot create directory ‘/root/input’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ejecutamos hadoop jar con el fin de ejecutar uno de los ejemplos por defecto, en este caso el grep que busca expresiones regulares dentro de los ficheros que le especifiquemos."
      ],
      "metadata": {
        "id": "FNMVFo_Df4f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "hadoop jar \\\n",
        "  /usr/local/hadoop-3.3.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.2.jar \\\n",
        "  grep ~/input ~/grep_example 'allowed[.]*'"
      ],
      "metadata": {
        "id": "iffiuEsZgJf9",
        "outputId": "38d7c6b2-540f-4355-91ee-43ea4632dc02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-24 20:22:39,352 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2023-11-24 20:22:39,609 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2023-11-24 20:22:39,610 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2023-11-24 20:22:39,898 INFO input.FileInputFormat: Total input files to process : 10\n",
            "2023-11-24 20:22:39,943 INFO mapreduce.JobSubmitter: number of splits:10\n",
            "2023-11-24 20:22:40,404 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local186942624_0001\n",
            "2023-11-24 20:22:40,404 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2023-11-24 20:22:40,674 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2023-11-24 20:22:40,674 INFO mapreduce.Job: Running job: job_local186942624_0001\n",
            "2023-11-24 20:22:40,684 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2023-11-24 20:22:40,693 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:40,693 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:40,694 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
            "2023-11-24 20:22:40,779 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2023-11-24 20:22:40,780 INFO mapred.LocalJobRunner: Starting task: attempt_local186942624_0001_m_000000_0\n",
            "2023-11-24 20:22:40,822 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:40,823 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:40,854 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:40,863 INFO mapred.MapTask: Processing split: file:/root/input/hadoop-policy.xml:0+11765\n",
            "2023-11-24 20:22:40,964 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-11-24 20:22:40,964 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-11-24 20:22:40,964 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-11-24 20:22:40,964 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-11-24 20:22:40,964 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-11-24 20:22:40,970 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-11-24 20:22:41,002 INFO mapred.LocalJobRunner: \n",
            "2023-11-24 20:22:41,003 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-11-24 20:22:41,003 INFO mapred.MapTask: Spilling map output\n",
            "2023-11-24 20:22:41,003 INFO mapred.MapTask: bufstart = 0; bufend = 374; bufvoid = 104857600\n",
            "2023-11-24 20:22:41,003 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214312(104857248); length = 85/6553600\n",
            "2023-11-24 20:22:41,021 INFO mapred.MapTask: Finished spill 0\n",
            "2023-11-24 20:22:41,035 INFO mapred.Task: Task:attempt_local186942624_0001_m_000000_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:41,040 INFO mapred.LocalJobRunner: map\n",
            "2023-11-24 20:22:41,040 INFO mapred.Task: Task 'attempt_local186942624_0001_m_000000_0' done.\n",
            "2023-11-24 20:22:41,049 INFO mapred.Task: Final Counters for attempt_local186942624_0001_m_000000_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=293932\n",
            "\t\tFILE: Number of bytes written=916627\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=275\n",
            "\t\tMap output records=22\n",
            "\t\tMap output bytes=374\n",
            "\t\tMap output materialized bytes=25\n",
            "\t\tInput split bytes=99\n",
            "\t\tCombine input records=22\n",
            "\t\tCombine output records=1\n",
            "\t\tSpilled Records=1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=348127232\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=11765\n",
            "2023-11-24 20:22:41,050 INFO mapred.LocalJobRunner: Finishing task: attempt_local186942624_0001_m_000000_0\n",
            "2023-11-24 20:22:41,051 INFO mapred.LocalJobRunner: Starting task: attempt_local186942624_0001_m_000001_0\n",
            "2023-11-24 20:22:41,053 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:41,053 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:41,053 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:41,055 INFO mapred.MapTask: Processing split: file:/root/input/capacity-scheduler.xml:0+9213\n",
            "2023-11-24 20:22:41,101 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-11-24 20:22:41,101 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-11-24 20:22:41,101 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-11-24 20:22:41,101 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-11-24 20:22:41,101 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-11-24 20:22:41,111 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-11-24 20:22:41,137 INFO mapred.LocalJobRunner: \n",
            "2023-11-24 20:22:41,141 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-11-24 20:22:41,141 INFO mapred.MapTask: Spilling map output\n",
            "2023-11-24 20:22:41,141 INFO mapred.MapTask: bufstart = 0; bufend = 16; bufvoid = 104857600\n",
            "2023-11-24 20:22:41,141 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
            "2023-11-24 20:22:41,144 INFO mapred.MapTask: Finished spill 0\n",
            "2023-11-24 20:22:41,150 INFO mapred.Task: Task:attempt_local186942624_0001_m_000001_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:41,153 INFO mapred.LocalJobRunner: map\n",
            "2023-11-24 20:22:41,153 INFO mapred.Task: Task 'attempt_local186942624_0001_m_000001_0' done.\n",
            "2023-11-24 20:22:41,153 INFO mapred.Task: Final Counters for attempt_local186942624_0001_m_000001_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=304137\n",
            "\t\tFILE: Number of bytes written=916683\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=244\n",
            "\t\tMap output records=1\n",
            "\t\tMap output bytes=16\n",
            "\t\tMap output materialized bytes=24\n",
            "\t\tInput split bytes=104\n",
            "\t\tCombine input records=1\n",
            "\t\tCombine output records=1\n",
            "\t\tSpilled Records=1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=19\n",
            "\t\tTotal committed heap usage (bytes)=348127232\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=9213\n",
            "2023-11-24 20:22:41,154 INFO mapred.LocalJobRunner: Finishing task: attempt_local186942624_0001_m_000001_0\n",
            "2023-11-24 20:22:41,154 INFO mapred.LocalJobRunner: Starting task: attempt_local186942624_0001_m_000002_0\n",
            "2023-11-24 20:22:41,155 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:41,155 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:41,156 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:41,157 INFO mapred.MapTask: Processing split: file:/root/input/kms-acls.xml:0+3518\n",
            "2023-11-24 20:22:41,206 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-11-24 20:22:41,206 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-11-24 20:22:41,206 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-11-24 20:22:41,206 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-11-24 20:22:41,206 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-11-24 20:22:41,207 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-11-24 20:22:41,213 INFO mapred.LocalJobRunner: \n",
            "2023-11-24 20:22:41,214 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-11-24 20:22:41,218 INFO mapred.Task: Task:attempt_local186942624_0001_m_000002_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:41,220 INFO mapred.LocalJobRunner: map\n",
            "2023-11-24 20:22:41,220 INFO mapred.Task: Task 'attempt_local186942624_0001_m_000002_0' done.\n",
            "2023-11-24 20:22:41,223 INFO mapred.Task: Final Counters for attempt_local186942624_0001_m_000002_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=308647\n",
            "\t\tFILE: Number of bytes written=916721\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=135\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=94\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=19\n",
            "\t\tTotal committed heap usage (bytes)=348127232\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=3518\n",
            "2023-11-24 20:22:41,223 INFO mapred.LocalJobRunner: Finishing task: attempt_local186942624_0001_m_000002_0\n",
            "2023-11-24 20:22:41,223 INFO mapred.LocalJobRunner: Starting task: attempt_local186942624_0001_m_000003_0\n",
            "2023-11-24 20:22:41,235 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:41,236 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:41,236 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:41,245 INFO mapred.MapTask: Processing split: file:/root/input/hdfs-site.xml:0+775\n",
            "2023-11-24 20:22:41,314 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-11-24 20:22:41,314 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-11-24 20:22:41,314 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-11-24 20:22:41,314 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-11-24 20:22:41,314 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-11-24 20:22:41,319 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-11-24 20:22:41,326 INFO mapred.LocalJobRunner: \n",
            "2023-11-24 20:22:41,328 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-11-24 20:22:41,339 INFO mapred.Task: Task:attempt_local186942624_0001_m_000003_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:41,342 INFO mapred.LocalJobRunner: map\n",
            "2023-11-24 20:22:41,342 INFO mapred.Task: Task 'attempt_local186942624_0001_m_000003_0' done.\n",
            "2023-11-24 20:22:41,343 INFO mapred.Task: Final Counters for attempt_local186942624_0001_m_000003_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=310414\n",
            "\t\tFILE: Number of bytes written=916759\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=21\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=95\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=348127232\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=775\n",
            "2023-11-24 20:22:41,343 INFO mapred.LocalJobRunner: Finishing task: attempt_local186942624_0001_m_000003_0\n",
            "2023-11-24 20:22:41,345 INFO mapred.LocalJobRunner: Starting task: attempt_local186942624_0001_m_000004_0\n",
            "2023-11-24 20:22:41,346 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:41,346 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:41,347 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:41,354 INFO mapred.MapTask: Processing split: file:/root/input/core-site.xml:0+774\n",
            "2023-11-24 20:22:41,388 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-11-24 20:22:41,388 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-11-24 20:22:41,388 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-11-24 20:22:41,388 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-11-24 20:22:41,388 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-11-24 20:22:41,389 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-11-24 20:22:41,393 INFO mapred.LocalJobRunner: \n",
            "2023-11-24 20:22:41,393 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-11-24 20:22:41,397 INFO mapred.Task: Task:attempt_local186942624_0001_m_000004_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:41,398 INFO mapred.LocalJobRunner: map\n",
            "2023-11-24 20:22:41,399 INFO mapred.Task: Task 'attempt_local186942624_0001_m_000004_0' done.\n",
            "2023-11-24 20:22:41,399 INFO mapred.Task: Final Counters for attempt_local186942624_0001_m_000004_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=312180\n",
            "\t\tFILE: Number of bytes written=916797\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=20\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=95\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=8\n",
            "\t\tTotal committed heap usage (bytes)=430964736\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=774\n",
            "2023-11-24 20:22:41,399 INFO mapred.LocalJobRunner: Finishing task: attempt_local186942624_0001_m_000004_0\n",
            "2023-11-24 20:22:41,400 INFO mapred.LocalJobRunner: Starting task: attempt_local186942624_0001_m_000005_0\n",
            "2023-11-24 20:22:41,405 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:41,405 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:41,410 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:41,412 INFO mapred.MapTask: Processing split: file:/root/input/mapred-site.xml:0+758\n",
            "2023-11-24 20:22:41,443 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-11-24 20:22:41,443 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-11-24 20:22:41,443 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-11-24 20:22:41,443 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-11-24 20:22:41,443 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-11-24 20:22:41,445 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-11-24 20:22:41,453 INFO mapred.LocalJobRunner: \n",
            "2023-11-24 20:22:41,453 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-11-24 20:22:41,457 INFO mapred.Task: Task:attempt_local186942624_0001_m_000005_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:41,459 INFO mapred.LocalJobRunner: map\n",
            "2023-11-24 20:22:41,460 INFO mapred.Task: Task 'attempt_local186942624_0001_m_000005_0' done.\n",
            "2023-11-24 20:22:41,467 INFO mapred.Task: Final Counters for attempt_local186942624_0001_m_000005_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=313930\n",
            "\t\tFILE: Number of bytes written=916835\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=21\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=97\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=430964736\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=758\n",
            "2023-11-24 20:22:41,467 INFO mapred.LocalJobRunner: Finishing task: attempt_local186942624_0001_m_000005_0\n",
            "2023-11-24 20:22:41,469 INFO mapred.LocalJobRunner: Starting task: attempt_local186942624_0001_m_000006_0\n",
            "2023-11-24 20:22:41,472 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:41,472 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:41,473 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:41,474 INFO mapred.MapTask: Processing split: file:/root/input/yarn-site.xml:0+690\n",
            "2023-11-24 20:22:41,503 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-11-24 20:22:41,503 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-11-24 20:22:41,503 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-11-24 20:22:41,503 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-11-24 20:22:41,503 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-11-24 20:22:41,506 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-11-24 20:22:41,514 INFO mapred.LocalJobRunner: \n",
            "2023-11-24 20:22:41,514 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-11-24 20:22:41,531 INFO mapred.Task: Task:attempt_local186942624_0001_m_000006_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:41,533 INFO mapred.LocalJobRunner: map\n",
            "2023-11-24 20:22:41,534 INFO mapred.Task: Task 'attempt_local186942624_0001_m_000006_0' done.\n",
            "2023-11-24 20:22:41,535 INFO mapred.Task: Final Counters for attempt_local186942624_0001_m_000006_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=315100\n",
            "\t\tFILE: Number of bytes written=916873\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=19\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=95\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=8\n",
            "\t\tTotal committed heap usage (bytes)=430964736\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=690\n",
            "2023-11-24 20:22:41,536 INFO mapred.LocalJobRunner: Finishing task: attempt_local186942624_0001_m_000006_0\n",
            "2023-11-24 20:22:41,536 INFO mapred.LocalJobRunner: Starting task: attempt_local186942624_0001_m_000007_0\n",
            "2023-11-24 20:22:41,542 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:41,542 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:41,542 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:41,544 INFO mapred.MapTask: Processing split: file:/root/input/hdfs-rbf-site.xml:0+683\n",
            "2023-11-24 20:22:41,568 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-11-24 20:22:41,568 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-11-24 20:22:41,568 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-11-24 20:22:41,568 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-11-24 20:22:41,568 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-11-24 20:22:41,569 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-11-24 20:22:41,573 INFO mapred.LocalJobRunner: \n",
            "2023-11-24 20:22:41,573 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-11-24 20:22:41,582 INFO mapred.Task: Task:attempt_local186942624_0001_m_000007_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:41,597 INFO mapred.LocalJobRunner: map\n",
            "2023-11-24 20:22:41,597 INFO mapred.Task: Task 'attempt_local186942624_0001_m_000007_0' done.\n",
            "2023-11-24 20:22:41,597 INFO mapred.Task: Final Counters for attempt_local186942624_0001_m_000007_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=316263\n",
            "\t\tFILE: Number of bytes written=916911\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=20\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=99\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=8\n",
            "\t\tTotal committed heap usage (bytes)=430964736\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=683\n",
            "2023-11-24 20:22:41,597 INFO mapred.LocalJobRunner: Finishing task: attempt_local186942624_0001_m_000007_0\n",
            "2023-11-24 20:22:41,597 INFO mapred.LocalJobRunner: Starting task: attempt_local186942624_0001_m_000008_0\n",
            "2023-11-24 20:22:41,610 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:41,610 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:41,611 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:41,613 INFO mapred.MapTask: Processing split: file:/root/input/kms-site.xml:0+682\n",
            "2023-11-24 20:22:41,644 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-11-24 20:22:41,645 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-11-24 20:22:41,645 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-11-24 20:22:41,645 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-11-24 20:22:41,645 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-11-24 20:22:41,646 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-11-24 20:22:41,650 INFO mapred.LocalJobRunner: \n",
            "2023-11-24 20:22:41,651 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-11-24 20:22:41,654 INFO mapred.Task: Task:attempt_local186942624_0001_m_000008_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:41,660 INFO mapred.LocalJobRunner: map\n",
            "2023-11-24 20:22:41,660 INFO mapred.Task: Task 'attempt_local186942624_0001_m_000008_0' done.\n",
            "2023-11-24 20:22:41,661 INFO mapred.Task: Final Counters for attempt_local186942624_0001_m_000008_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=317425\n",
            "\t\tFILE: Number of bytes written=916949\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=20\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=94\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=8\n",
            "\t\tTotal committed heap usage (bytes)=430964736\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=682\n",
            "2023-11-24 20:22:41,661 INFO mapred.LocalJobRunner: Finishing task: attempt_local186942624_0001_m_000008_0\n",
            "2023-11-24 20:22:41,662 INFO mapred.LocalJobRunner: Starting task: attempt_local186942624_0001_m_000009_0\n",
            "2023-11-24 20:22:41,670 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:41,670 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:41,670 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:41,672 INFO mapred.MapTask: Processing split: file:/root/input/httpfs-site.xml:0+620\n",
            "2023-11-24 20:22:41,682 INFO mapreduce.Job: Job job_local186942624_0001 running in uber mode : false\n",
            "2023-11-24 20:22:41,693 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-11-24 20:22:41,695 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-11-24 20:22:41,695 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-11-24 20:22:41,695 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-11-24 20:22:41,696 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-11-24 20:22:41,696 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-11-24 20:22:41,696 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-11-24 20:22:41,700 INFO mapred.LocalJobRunner: \n",
            "2023-11-24 20:22:41,700 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-11-24 20:22:41,704 INFO mapred.Task: Task:attempt_local186942624_0001_m_000009_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:41,706 INFO mapred.LocalJobRunner: map\n",
            "2023-11-24 20:22:41,707 INFO mapred.Task: Task 'attempt_local186942624_0001_m_000009_0' done.\n",
            "2023-11-24 20:22:41,707 INFO mapred.Task: Final Counters for attempt_local186942624_0001_m_000009_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=318525\n",
            "\t\tFILE: Number of bytes written=916987\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=17\n",
            "\t\tMap output records=0\n",
            "\t\tMap output bytes=0\n",
            "\t\tMap output materialized bytes=6\n",
            "\t\tInput split bytes=97\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=430964736\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=620\n",
            "2023-11-24 20:22:41,707 INFO mapred.LocalJobRunner: Finishing task: attempt_local186942624_0001_m_000009_0\n",
            "2023-11-24 20:22:41,707 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2023-11-24 20:22:41,710 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2023-11-24 20:22:41,710 INFO mapred.LocalJobRunner: Starting task: attempt_local186942624_0001_r_000000_0\n",
            "2023-11-24 20:22:41,732 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:41,732 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:41,732 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:41,737 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@40a9ab9c\n",
            "2023-11-24 20:22:41,739 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-11-24 20:22:41,786 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2023-11-24 20:22:41,792 INFO reduce.EventFetcher: attempt_local186942624_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2023-11-24 20:22:41,847 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local186942624_0001_m_000008_0 decomp: 2 len: 6 to MEMORY\n",
            "2023-11-24 20:22:41,852 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local186942624_0001_m_000008_0\n",
            "2023-11-24 20:22:41,857 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2\n",
            "2023-11-24 20:22:41,868 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local186942624_0001_m_000002_0 decomp: 2 len: 6 to MEMORY\n",
            "2023-11-24 20:22:41,871 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local186942624_0001_m_000002_0\n",
            "2023-11-24 20:22:41,871 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4\n",
            "2023-11-24 20:22:41,873 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local186942624_0001_m_000005_0 decomp: 2 len: 6 to MEMORY\n",
            "2023-11-24 20:22:41,875 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local186942624_0001_m_000005_0\n",
            "2023-11-24 20:22:41,875 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6\n",
            "2023-11-24 20:22:41,876 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local186942624_0001_m_000004_0 decomp: 2 len: 6 to MEMORY\n",
            "2023-11-24 20:22:41,880 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local186942624_0001_m_000004_0\n",
            "2023-11-24 20:22:41,880 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8\n",
            "2023-11-24 20:22:41,886 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local186942624_0001_m_000007_0 decomp: 2 len: 6 to MEMORY\n",
            "2023-11-24 20:22:41,888 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local186942624_0001_m_000007_0\n",
            "2023-11-24 20:22:41,888 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->10\n",
            "2023-11-24 20:22:41,890 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local186942624_0001_m_000001_0 decomp: 20 len: 24 to MEMORY\n",
            "2023-11-24 20:22:41,891 INFO reduce.InMemoryMapOutput: Read 20 bytes from map-output for attempt_local186942624_0001_m_000001_0\n",
            "2023-11-24 20:22:41,891 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 6, commitMemory -> 10, usedMemory ->30\n",
            "2023-11-24 20:22:41,893 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local186942624_0001_m_000000_0 decomp: 21 len: 25 to MEMORY\n",
            "2023-11-24 20:22:41,894 INFO reduce.InMemoryMapOutput: Read 21 bytes from map-output for attempt_local186942624_0001_m_000000_0\n",
            "2023-11-24 20:22:41,894 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 21, inMemoryMapOutputs.size() -> 7, commitMemory -> 30, usedMemory ->51\n",
            "2023-11-24 20:22:41,896 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local186942624_0001_m_000003_0 decomp: 2 len: 6 to MEMORY\n",
            "2023-11-24 20:22:41,897 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local186942624_0001_m_000003_0\n",
            "2023-11-24 20:22:41,897 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 8, commitMemory -> 51, usedMemory ->53\n",
            "2023-11-24 20:22:41,899 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local186942624_0001_m_000006_0 decomp: 2 len: 6 to MEMORY\n",
            "2023-11-24 20:22:41,900 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local186942624_0001_m_000006_0\n",
            "2023-11-24 20:22:41,900 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 9, commitMemory -> 53, usedMemory ->55\n",
            "2023-11-24 20:22:41,901 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local186942624_0001_m_000009_0 decomp: 2 len: 6 to MEMORY\n",
            "2023-11-24 20:22:41,904 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local186942624_0001_m_000009_0\n",
            "2023-11-24 20:22:41,904 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 10, commitMemory -> 55, usedMemory ->57\n",
            "2023-11-24 20:22:41,911 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2023-11-24 20:22:41,912 INFO mapred.LocalJobRunner: 10 / 10 copied.\n",
            "2023-11-24 20:22:41,912 INFO reduce.MergeManagerImpl: finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2023-11-24 20:22:41,919 INFO mapred.Merger: Merging 10 sorted segments\n",
            "2023-11-24 20:22:41,920 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 20 bytes\n",
            "2023-11-24 20:22:41,921 INFO reduce.MergeManagerImpl: Merged 10 segments, 57 bytes to disk to satisfy reduce memory limit\n",
            "2023-11-24 20:22:41,921 INFO reduce.MergeManagerImpl: Merging 1 files, 43 bytes from disk\n",
            "2023-11-24 20:22:41,922 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2023-11-24 20:22:41,922 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2023-11-24 20:22:41,922 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n",
            "2023-11-24 20:22:41,924 INFO mapred.LocalJobRunner: 10 / 10 copied.\n",
            "2023-11-24 20:22:41,963 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2023-11-24 20:22:41,969 INFO mapred.Task: Task:attempt_local186942624_0001_r_000000_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:41,970 INFO mapred.LocalJobRunner: 10 / 10 copied.\n",
            "2023-11-24 20:22:41,971 INFO mapred.Task: Task attempt_local186942624_0001_r_000000_0 is allowed to commit now\n",
            "2023-11-24 20:22:41,972 INFO output.FileOutputCommitter: Saved output of task 'attempt_local186942624_0001_r_000000_0' to file:/content/grep-temp-679174834\n",
            "2023-11-24 20:22:41,973 INFO mapred.LocalJobRunner: reduce > reduce\n",
            "2023-11-24 20:22:41,975 INFO mapred.Task: Task 'attempt_local186942624_0001_r_000000_0' done.\n",
            "2023-11-24 20:22:41,976 INFO mapred.Task: Final Counters for attempt_local186942624_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=318985\n",
            "\t\tFILE: Number of bytes written=917177\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=97\n",
            "\t\tReduce input records=2\n",
            "\t\tReduce output records=2\n",
            "\t\tSpilled Records=2\n",
            "\t\tShuffled Maps =10\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=10\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=430964736\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=147\n",
            "2023-11-24 20:22:41,976 INFO mapred.LocalJobRunner: Finishing task: attempt_local186942624_0001_r_000000_0\n",
            "2023-11-24 20:22:41,976 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2023-11-24 20:22:42,700 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2023-11-24 20:22:42,700 INFO mapreduce.Job: Job job_local186942624_0001 completed successfully\n",
            "2023-11-24 20:22:42,732 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=3429538\n",
            "\t\tFILE: Number of bytes written=10085319\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=792\n",
            "\t\tMap output records=23\n",
            "\t\tMap output bytes=390\n",
            "\t\tMap output materialized bytes=97\n",
            "\t\tInput split bytes=969\n",
            "\t\tCombine input records=23\n",
            "\t\tCombine output records=2\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=97\n",
            "\t\tReduce input records=2\n",
            "\t\tReduce output records=2\n",
            "\t\tSpilled Records=4\n",
            "\t\tShuffled Maps =10\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=10\n",
            "\t\tGC time elapsed (ms)=70\n",
            "\t\tTotal committed heap usage (bytes)=4409262080\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=29478\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=147\n",
            "2023-11-24 20:22:42,771 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-11-24 20:22:42,784 INFO input.FileInputFormat: Total input files to process : 1\n",
            "2023-11-24 20:22:42,787 INFO mapreduce.JobSubmitter: number of splits:1\n",
            "2023-11-24 20:22:42,820 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1732858838_0002\n",
            "2023-11-24 20:22:42,820 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2023-11-24 20:22:42,962 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2023-11-24 20:22:42,963 INFO mapreduce.Job: Running job: job_local1732858838_0002\n",
            "2023-11-24 20:22:42,963 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2023-11-24 20:22:42,964 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:42,964 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:42,964 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
            "2023-11-24 20:22:42,970 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2023-11-24 20:22:42,970 INFO mapred.LocalJobRunner: Starting task: attempt_local1732858838_0002_m_000000_0\n",
            "2023-11-24 20:22:42,972 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:42,972 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:42,972 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:42,976 INFO mapred.MapTask: Processing split: file:/content/grep-temp-679174834/part-r-00000:0+135\n",
            "2023-11-24 20:22:43,003 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-11-24 20:22:43,003 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-11-24 20:22:43,003 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-11-24 20:22:43,003 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-11-24 20:22:43,003 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-11-24 20:22:43,015 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-11-24 20:22:43,031 INFO mapred.LocalJobRunner: \n",
            "2023-11-24 20:22:43,032 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-11-24 20:22:43,032 INFO mapred.MapTask: Spilling map output\n",
            "2023-11-24 20:22:43,032 INFO mapred.MapTask: bufstart = 0; bufend = 33; bufvoid = 104857600\n",
            "2023-11-24 20:22:43,032 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
            "2023-11-24 20:22:43,034 INFO mapred.MapTask: Finished spill 0\n",
            "2023-11-24 20:22:43,045 INFO mapred.Task: Task:attempt_local1732858838_0002_m_000000_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:43,048 INFO mapred.LocalJobRunner: map\n",
            "2023-11-24 20:22:43,048 INFO mapred.Task: Task 'attempt_local1732858838_0002_m_000000_0' done.\n",
            "2023-11-24 20:22:43,048 INFO mapred.Task: Final Counters for attempt_local1732858838_0002_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=600286\n",
            "\t\tFILE: Number of bytes written=1834580\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=2\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=33\n",
            "\t\tMap output materialized bytes=43\n",
            "\t\tInput split bytes=111\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=2\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=9\n",
            "\t\tTotal committed heap usage (bytes)=430964736\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=147\n",
            "2023-11-24 20:22:43,048 INFO mapred.LocalJobRunner: Finishing task: attempt_local1732858838_0002_m_000000_0\n",
            "2023-11-24 20:22:43,048 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2023-11-24 20:22:43,050 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2023-11-24 20:22:43,050 INFO mapred.LocalJobRunner: Starting task: attempt_local1732858838_0002_r_000000_0\n",
            "2023-11-24 20:22:43,054 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-11-24 20:22:43,054 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-11-24 20:22:43,054 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-11-24 20:22:43,054 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5a298b72\n",
            "2023-11-24 20:22:43,054 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-11-24 20:22:43,056 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2023-11-24 20:22:43,057 INFO reduce.EventFetcher: attempt_local1732858838_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2023-11-24 20:22:43,065 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1732858838_0002_m_000000_0 decomp: 39 len: 43 to MEMORY\n",
            "2023-11-24 20:22:43,066 INFO reduce.InMemoryMapOutput: Read 39 bytes from map-output for attempt_local1732858838_0002_m_000000_0\n",
            "2023-11-24 20:22:43,066 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 39, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->39\n",
            "2023-11-24 20:22:43,067 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2023-11-24 20:22:43,067 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2023-11-24 20:22:43,068 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2023-11-24 20:22:43,068 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2023-11-24 20:22:43,069 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n",
            "2023-11-24 20:22:43,069 INFO reduce.MergeManagerImpl: Merged 1 segments, 39 bytes to disk to satisfy reduce memory limit\n",
            "2023-11-24 20:22:43,070 INFO reduce.MergeManagerImpl: Merging 1 files, 43 bytes from disk\n",
            "2023-11-24 20:22:43,070 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2023-11-24 20:22:43,070 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2023-11-24 20:22:43,070 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n",
            "2023-11-24 20:22:43,071 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2023-11-24 20:22:43,074 INFO mapred.Task: Task:attempt_local1732858838_0002_r_000000_0 is done. And is in the process of committing\n",
            "2023-11-24 20:22:43,074 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2023-11-24 20:22:43,075 INFO mapred.Task: Task attempt_local1732858838_0002_r_000000_0 is allowed to commit now\n",
            "2023-11-24 20:22:43,076 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1732858838_0002_r_000000_0' to file:/root/grep_example\n",
            "2023-11-24 20:22:43,076 INFO mapred.LocalJobRunner: reduce > reduce\n",
            "2023-11-24 20:22:43,077 INFO mapred.Task: Task 'attempt_local1732858838_0002_r_000000_0' done.\n",
            "2023-11-24 20:22:43,077 INFO mapred.Task: Final Counters for attempt_local1732858838_0002_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=600404\n",
            "\t\tFILE: Number of bytes written=1834657\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=43\n",
            "\t\tReduce input records=2\n",
            "\t\tReduce output records=2\n",
            "\t\tSpilled Records=2\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=430964736\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=34\n",
            "2023-11-24 20:22:43,077 INFO mapred.LocalJobRunner: Finishing task: attempt_local1732858838_0002_r_000000_0\n",
            "2023-11-24 20:22:43,077 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2023-11-24 20:22:43,963 INFO mapreduce.Job: Job job_local1732858838_0002 running in uber mode : false\n",
            "2023-11-24 20:22:43,963 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2023-11-24 20:22:43,964 INFO mapreduce.Job: Job job_local1732858838_0002 completed successfully\n",
            "2023-11-24 20:22:43,966 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1200690\n",
            "\t\tFILE: Number of bytes written=3669237\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=2\n",
            "\t\tMap output records=2\n",
            "\t\tMap output bytes=33\n",
            "\t\tMap output materialized bytes=43\n",
            "\t\tInput split bytes=111\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=2\n",
            "\t\tReduce shuffle bytes=43\n",
            "\t\tReduce input records=2\n",
            "\t\tReduce output records=2\n",
            "\t\tSpilled Records=4\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=9\n",
            "\t\tTotal committed heap usage (bytes)=861929472\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=147\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ~/grep_example/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkteR8esgZTs",
        "outputId": "8feb0dfd-ed5c-45a8-8473-36aad0deb7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\tallowed.\n",
            "1\tallowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HDFS\n"
      ],
      "metadata": {
        "id": "2aHq4zezd-09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las siguientes sentencias únicamente sirven para probar comandos básicos de HDFS no para gestionar una Infraestructura que en Google Colab no existe, en este caso el sistema de archivos HDFS es el mismo que el local"
      ],
      "metadata": {
        "id": "KCkyAP77gkGi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPB6hnMc_Xeh"
      },
      "source": [
        "* Crear el directorio *prueba*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAGdEAYy_UDB"
      },
      "source": [
        "!hdfs dfs -mkdir prueba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt4ovs9-vC47"
      },
      "source": [
        "- Crear un fichero local :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOCZWC2JvUOH",
        "outputId": "0fc16300-50c0-423d-fc3a-51d577c64477"
      },
      "source": [
        "%%bash\n",
        "echo \"Ejemplo de HDFS\" > user.txt\n",
        "echo `date` >> user.txt\n",
        "cat user.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de HDFS\n",
            "Wed Mar 16 11:36:08 UTC 2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk4NIb_gvdNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60fb3e47-28ed-4a71-fa81-c3572b6e5dba"
      },
      "source": [
        "!hdfs dfs -put user.txt prueba/\n",
        "!hdfs dfs -ls prueba"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "put: `prueba/user.txt': File exists\n",
            "Found 1 items\n",
            "-rw-r--r--   1 root root         45 2022-03-16 11:37 prueba/user.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXxnK8JA_0_9"
      },
      "source": [
        "- Mostrar su contenido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3C_cq5OvxNV",
        "outputId": "796f4cfd-bc82-4739-a641-5c9b19ecc9d4"
      },
      "source": [
        "!hdfs dfs -cat prueba/user.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de HDFS\n",
            "Wed Mar 16 11:36:08 UTC 2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRKP6oHOHcNL",
        "outputId": "d8eb378f-0046-4a21-ef1f-192d1065be93"
      },
      "source": [
        "%%bash\n",
        "hdfs dfs -tail prueba/user.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de HDFS\n",
            "Wed Mar 16 11:36:08 UTC 2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejecute los comandos utilizados en la tarea de \"Comandos HDFS\" en Google Colab**"
      ],
      "metadata": {
        "id": "yo6EaM2ZAqrE"
      }
    }
  ]
}